{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='1111.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "mbNqdBK5mZXA"
   },
   "outputs": [],
   "source": [
    "#pip install pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "HDj6qYrNnGoE"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "t3VD3ANqnTrE"
   },
   "outputs": [],
   "source": [
    "#Regression AutoMl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "D0JY6Dl4nZQb"
   },
   "outputs": [],
   "source": [
    "from pycaret.regression import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "6m088K49nh1T"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "id": "-UOHxRRDnrgh",
    "outputId": "7613afab-3b43-487d-db9a-4a4a5c7ee5e3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-953809c6-510d-421d-bd50-830c72230886\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>store_sales(in millions)</th>\n",
       "      <th>unit_sales(in millions)</th>\n",
       "      <th>total_children</th>\n",
       "      <th>num_children_at_home</th>\n",
       "      <th>avg_cars_at home(approx).1</th>\n",
       "      <th>gross_weight</th>\n",
       "      <th>recyclable_package</th>\n",
       "      <th>low_fat</th>\n",
       "      <th>units_per_case</th>\n",
       "      <th>store_sqft</th>\n",
       "      <th>coffee_bar</th>\n",
       "      <th>video_store</th>\n",
       "      <th>salad_bar</th>\n",
       "      <th>prepared_food</th>\n",
       "      <th>florist</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8.61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>36509.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28206.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>121.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>14.08</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>21215.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4.02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>21215.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.13</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>27694.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>111.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-953809c6-510d-421d-bd50-830c72230886')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-953809c6-510d-421d-bd50-830c72230886 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-953809c6-510d-421d-bd50-830c72230886');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-79a77212-428e-48e1-a042-d3655bcfd97e\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-79a77212-428e-48e1-a042-d3655bcfd97e')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-79a77212-428e-48e1-a042-d3655bcfd97e button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   id  store_sales(in millions)  unit_sales(in millions)  total_children  \\\n",
       "0   0                      8.61                      3.0             2.0   \n",
       "1   1                      5.00                      2.0             4.0   \n",
       "2   2                     14.08                      4.0             0.0   \n",
       "3   3                      4.02                      3.0             5.0   \n",
       "4   4                      2.13                      3.0             5.0   \n",
       "\n",
       "   num_children_at_home  avg_cars_at home(approx).1  gross_weight  \\\n",
       "0                   2.0                         2.0         10.30   \n",
       "1                   0.0                         3.0          6.66   \n",
       "2                   0.0                         3.0         21.30   \n",
       "3                   0.0                         0.0         14.80   \n",
       "4                   0.0                         3.0         17.00   \n",
       "\n",
       "   recyclable_package  low_fat  units_per_case  store_sqft  coffee_bar  \\\n",
       "0                 1.0      0.0            32.0     36509.0         0.0   \n",
       "1                 1.0      0.0             1.0     28206.0         1.0   \n",
       "2                 1.0      0.0            26.0     21215.0         1.0   \n",
       "3                 0.0      1.0            36.0     21215.0         1.0   \n",
       "4                 1.0      1.0            20.0     27694.0         1.0   \n",
       "\n",
       "   video_store  salad_bar  prepared_food  florist    cost  \n",
       "0          0.0        0.0            0.0      0.0   62.09  \n",
       "1          0.0        0.0            0.0      0.0  121.80  \n",
       "2          0.0        0.0            0.0      0.0   83.51  \n",
       "3          0.0        0.0            0.0      0.0   66.78  \n",
       "4          1.0        1.0            1.0      1.0  111.51  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j5Aj8t-3Knfp",
    "outputId": "7faa2cb0-f3f3-42e8-903e-47dd7ba89b4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13393 entries, 0 to 13392\n",
      "Data columns (total 17 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   id                          13393 non-null  int64  \n",
      " 1   store_sales(in millions)    13393 non-null  float64\n",
      " 2   unit_sales(in millions)     13393 non-null  float64\n",
      " 3   total_children              13393 non-null  float64\n",
      " 4   num_children_at_home        13393 non-null  float64\n",
      " 5   avg_cars_at home(approx).1  13393 non-null  float64\n",
      " 6   gross_weight                13393 non-null  float64\n",
      " 7   recyclable_package          13393 non-null  float64\n",
      " 8   low_fat                     13393 non-null  float64\n",
      " 9   units_per_case              13393 non-null  float64\n",
      " 10  store_sqft                  13393 non-null  float64\n",
      " 11  coffee_bar                  13393 non-null  float64\n",
      " 12  video_store                 13393 non-null  float64\n",
      " 13  salad_bar                   13393 non-null  float64\n",
      " 14  prepared_food               13392 non-null  float64\n",
      " 15  florist                     13392 non-null  float64\n",
      " 16  cost                        13392 non-null  float64\n",
      "dtypes: float64(16), int64(1)\n",
      "memory usage: 1.7 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d6zxxxikLjKg",
    "outputId": "b7bd45ef-0d78-479e-d197-8706789e7be3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_store                   0.126914\n",
       "prepared_food                 0.113281\n",
       "florist                       0.113276\n",
       "salad_bar                     0.113038\n",
       "store_sqft                    0.057676\n",
       "coffee_bar                    0.052281\n",
       "unit_sales(in millions)       0.020210\n",
       "store_sales(in millions)      0.014536\n",
       "total_children                0.011394\n",
       "gross_weight                  0.009283\n",
       "id                            0.007971\n",
       "units_per_case                0.006677\n",
       "recyclable_package            0.002043\n",
       "low_fat                       0.013299\n",
       "num_children_at_home          0.017569\n",
       "avg_cars_at home(approx).1    0.021917\n",
       "cost                          1.000000\n",
       "Name: cost, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(df.corr(numeric_only=True)['cost'].sort_values(ascending=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "THpY1e45LjM2"
   },
   "outputs": [],
   "source": [
    "x=df[[\"video_store\",\"prepared_food\",\"florist\",\"salad_bar\",\"store_sqft\",\"cost\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "08w6_Jj1LjPu",
    "outputId": "8243a9a8-1d38-4f45-ea34-bb6ecf103c3c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-5cca65fe-56ab-4bd9-9f9f-68cc1a623239\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_store</th>\n",
       "      <th>prepared_food</th>\n",
       "      <th>florist</th>\n",
       "      <th>salad_bar</th>\n",
       "      <th>store_sqft</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36509.0</td>\n",
       "      <td>62.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28206.0</td>\n",
       "      <td>121.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21215.0</td>\n",
       "      <td>83.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21215.0</td>\n",
       "      <td>66.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27694.0</td>\n",
       "      <td>111.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13387</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27694.0</td>\n",
       "      <td>66.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13388</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23598.0</td>\n",
       "      <td>131.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13389</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21215.0</td>\n",
       "      <td>135.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13390</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23598.0</td>\n",
       "      <td>131.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13391</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21215.0</td>\n",
       "      <td>138.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13392 rows Ã— 6 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5cca65fe-56ab-4bd9-9f9f-68cc1a623239')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-5cca65fe-56ab-4bd9-9f9f-68cc1a623239 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-5cca65fe-56ab-4bd9-9f9f-68cc1a623239');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-b442a142-160d-4f35-9eb9-c88bdbc93e39\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b442a142-160d-4f35-9eb9-c88bdbc93e39')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-b442a142-160d-4f35-9eb9-c88bdbc93e39 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "  <div id=\"id_94902b77-f8b2-492e-8ec0-e99a131498c2\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('x')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_94902b77-f8b2-492e-8ec0-e99a131498c2 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('x');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "       video_store  prepared_food  florist  salad_bar  store_sqft    cost\n",
       "0              0.0            0.0      0.0        0.0     36509.0   62.09\n",
       "1              0.0            0.0      0.0        0.0     28206.0  121.80\n",
       "2              0.0            0.0      0.0        0.0     21215.0   83.51\n",
       "3              0.0            0.0      0.0        0.0     21215.0   66.78\n",
       "4              1.0            1.0      1.0        1.0     27694.0  111.51\n",
       "...            ...            ...      ...        ...         ...     ...\n",
       "13387          1.0            1.0      1.0        1.0     27694.0   66.27\n",
       "13388          0.0            0.0      1.0        0.0     23598.0  131.81\n",
       "13389          0.0            0.0      0.0        0.0     21215.0  135.80\n",
       "13390          0.0            0.0      1.0        0.0     23598.0  131.81\n",
       "13391          0.0            0.0      0.0        0.0     21215.0  138.53\n",
       "\n",
       "[13392 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "cdDy-sGiK9AL"
   },
   "outputs": [],
   "source": [
    "df= df.dropna(subset=['cost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 663
    },
    "id": "LQhEAGwyntZr",
    "outputId": "e2eb5e2e-5653-41bf-c3f0-38180ac59e6f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_16b15_row8_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_16b15\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_16b15_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_16b15_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_16b15_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_16b15_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_16b15_row0_col1\" class=\"data row0 col1\" >2124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_16b15_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_16b15_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_16b15_row1_col1\" class=\"data row1 col1\" >cost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_16b15_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_16b15_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_16b15_row2_col1\" class=\"data row2 col1\" >Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_16b15_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_16b15_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_16b15_row3_col1\" class=\"data row3 col1\" >(13392, 17)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_16b15_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_16b15_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_16b15_row4_col1\" class=\"data row4 col1\" >(13392, 17)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_16b15_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_16b15_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_16b15_row5_col1\" class=\"data row5 col1\" >(9374, 17)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_16b15_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_16b15_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_16b15_row6_col1\" class=\"data row6 col1\" >(4018, 17)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_16b15_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_16b15_row7_col0\" class=\"data row7 col0\" >Numeric features</td>\n",
       "      <td id=\"T_16b15_row7_col1\" class=\"data row7 col1\" >16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_16b15_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_16b15_row8_col0\" class=\"data row8 col0\" >Preprocess</td>\n",
       "      <td id=\"T_16b15_row8_col1\" class=\"data row8 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_16b15_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_16b15_row9_col0\" class=\"data row9 col0\" >Imputation type</td>\n",
       "      <td id=\"T_16b15_row9_col1\" class=\"data row9 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_16b15_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_16b15_row10_col0\" class=\"data row10 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_16b15_row10_col1\" class=\"data row10 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_16b15_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_16b15_row11_col0\" class=\"data row11 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_16b15_row11_col1\" class=\"data row11 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_16b15_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_16b15_row12_col0\" class=\"data row12 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_16b15_row12_col1\" class=\"data row12 col1\" >KFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_16b15_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_16b15_row13_col0\" class=\"data row13 col0\" >Fold Number</td>\n",
       "      <td id=\"T_16b15_row13_col1\" class=\"data row13 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_16b15_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_16b15_row14_col0\" class=\"data row14 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_16b15_row14_col1\" class=\"data row14 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_16b15_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_16b15_row15_col0\" class=\"data row15 col0\" >Use GPU</td>\n",
       "      <td id=\"T_16b15_row15_col1\" class=\"data row15 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_16b15_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_16b15_row16_col0\" class=\"data row16 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_16b15_row16_col1\" class=\"data row16 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_16b15_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_16b15_row17_col0\" class=\"data row17 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_16b15_row17_col1\" class=\"data row17 col1\" >reg-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_16b15_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_16b15_row18_col0\" class=\"data row18 col0\" >USI</td>\n",
       "      <td id=\"T_16b15_row18_col1\" class=\"data row18 col1\" >0cbb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7b8d7642dcc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<pycaret.regression.oop.RegressionExperiment at 0x7b8d56717520>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setup(data=df,target='cost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 645,
     "referenced_widgets": [
      "2c67d6f583a44d0f9e683b4000a20690",
      "66df53e3d6594f4f8a1af397c9eba68a",
      "9a3ce94bfaaf4ba8aa90f90fc619fdc1",
      "1cc1b4a0b2114e70b604e0f1d824ea2a",
      "d1c66aff2674456b89ee0101135b8d68",
      "bd3319850a8042bba1f7e48cf15509a6",
      "0a3bafb7b08d44168524748f38526e70",
      "6f9cb4e1456d4ada9e3f98a6ff9f3b74",
      "f2e1cd89cb704c5e8c7537b32f1854a2",
      "df5d53147b624d9ca8a65f3c7dfa49f8",
      "5fce10c3f9374196969e555c7b13e6b4"
     ]
    },
    "id": "PmK8APGuoK8p",
    "outputId": "1942ca7a-3507-4f7c-db08-6301beb9574e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_18137 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_18137_row0_col0, #T_18137_row1_col0, #T_18137_row1_col1, #T_18137_row1_col2, #T_18137_row1_col3, #T_18137_row1_col4, #T_18137_row1_col5, #T_18137_row1_col6, #T_18137_row2_col0, #T_18137_row2_col1, #T_18137_row2_col2, #T_18137_row2_col3, #T_18137_row2_col4, #T_18137_row2_col5, #T_18137_row2_col6, #T_18137_row3_col0, #T_18137_row3_col1, #T_18137_row3_col2, #T_18137_row3_col3, #T_18137_row3_col4, #T_18137_row3_col5, #T_18137_row4_col0, #T_18137_row4_col1, #T_18137_row4_col2, #T_18137_row4_col3, #T_18137_row4_col4, #T_18137_row4_col5, #T_18137_row4_col6, #T_18137_row5_col0, #T_18137_row5_col1, #T_18137_row5_col2, #T_18137_row5_col3, #T_18137_row5_col4, #T_18137_row5_col5, #T_18137_row5_col6, #T_18137_row6_col0, #T_18137_row6_col1, #T_18137_row6_col2, #T_18137_row6_col3, #T_18137_row6_col4, #T_18137_row6_col5, #T_18137_row6_col6, #T_18137_row7_col0, #T_18137_row7_col1, #T_18137_row7_col2, #T_18137_row7_col3, #T_18137_row7_col4, #T_18137_row7_col5, #T_18137_row7_col6, #T_18137_row8_col0, #T_18137_row8_col1, #T_18137_row8_col2, #T_18137_row8_col3, #T_18137_row8_col4, #T_18137_row8_col5, #T_18137_row8_col6, #T_18137_row9_col0, #T_18137_row9_col1, #T_18137_row9_col2, #T_18137_row9_col3, #T_18137_row9_col4, #T_18137_row9_col5, #T_18137_row9_col6, #T_18137_row10_col0, #T_18137_row10_col1, #T_18137_row10_col2, #T_18137_row10_col3, #T_18137_row10_col4, #T_18137_row10_col5, #T_18137_row10_col6, #T_18137_row11_col0, #T_18137_row11_col1, #T_18137_row11_col2, #T_18137_row11_col3, #T_18137_row11_col4, #T_18137_row11_col5, #T_18137_row11_col6, #T_18137_row12_col0, #T_18137_row12_col1, #T_18137_row12_col2, #T_18137_row12_col3, #T_18137_row12_col4, #T_18137_row12_col5, #T_18137_row12_col6, #T_18137_row13_col0, #T_18137_row13_col1, #T_18137_row13_col2, #T_18137_row13_col3, #T_18137_row13_col4, #T_18137_row13_col5, #T_18137_row13_col6, #T_18137_row14_col0, #T_18137_row14_col1, #T_18137_row14_col2, #T_18137_row14_col3, #T_18137_row14_col4, #T_18137_row14_col5, #T_18137_row14_col6, #T_18137_row15_col0, #T_18137_row15_col1, #T_18137_row15_col2, #T_18137_row15_col3, #T_18137_row15_col4, #T_18137_row15_col5, #T_18137_row15_col6, #T_18137_row16_col0, #T_18137_row16_col1, #T_18137_row16_col2, #T_18137_row16_col3, #T_18137_row16_col4, #T_18137_row16_col5, #T_18137_row16_col6, #T_18137_row17_col0, #T_18137_row17_col1, #T_18137_row17_col2, #T_18137_row17_col3, #T_18137_row17_col4, #T_18137_row17_col5, #T_18137_row17_col6, #T_18137_row18_col0, #T_18137_row18_col1, #T_18137_row18_col2, #T_18137_row18_col3, #T_18137_row18_col4, #T_18137_row18_col5, #T_18137_row18_col6 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_18137_row0_col1, #T_18137_row0_col2, #T_18137_row0_col3, #T_18137_row0_col4, #T_18137_row0_col5, #T_18137_row0_col6, #T_18137_row3_col6 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_18137_row0_col7, #T_18137_row1_col7, #T_18137_row2_col7, #T_18137_row3_col7, #T_18137_row4_col7, #T_18137_row5_col7, #T_18137_row6_col7, #T_18137_row7_col7, #T_18137_row9_col7, #T_18137_row10_col7, #T_18137_row11_col7, #T_18137_row13_col7, #T_18137_row14_col7, #T_18137_row15_col7, #T_18137_row16_col7, #T_18137_row17_col7, #T_18137_row18_col7 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_18137_row8_col7, #T_18137_row12_col7 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_18137\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_18137_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_18137_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th id=\"T_18137_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_18137_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n",
       "      <th id=\"T_18137_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n",
       "      <th id=\"T_18137_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n",
       "      <th id=\"T_18137_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n",
       "      <th id=\"T_18137_level0_col7\" class=\"col_heading level0 col7\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_18137_level0_row0\" class=\"row_heading level0 row0\" >gbr</th>\n",
       "      <td id=\"T_18137_row0_col0\" class=\"data row0 col0\" >Gradient Boosting Regressor</td>\n",
       "      <td id=\"T_18137_row0_col1\" class=\"data row0 col1\" >25.2103</td>\n",
       "      <td id=\"T_18137_row0_col2\" class=\"data row0 col2\" >854.2038</td>\n",
       "      <td id=\"T_18137_row0_col3\" class=\"data row0 col3\" >29.2241</td>\n",
       "      <td id=\"T_18137_row0_col4\" class=\"data row0 col4\" >0.0503</td>\n",
       "      <td id=\"T_18137_row0_col5\" class=\"data row0 col5\" >0.3120</td>\n",
       "      <td id=\"T_18137_row0_col6\" class=\"data row0 col6\" >0.2913</td>\n",
       "      <td id=\"T_18137_row0_col7\" class=\"data row0 col7\" >1.2740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_18137_level0_row1\" class=\"row_heading level0 row1\" >ada</th>\n",
       "      <td id=\"T_18137_row1_col0\" class=\"data row1 col0\" >AdaBoost Regressor</td>\n",
       "      <td id=\"T_18137_row1_col1\" class=\"data row1 col1\" >25.4920</td>\n",
       "      <td id=\"T_18137_row1_col2\" class=\"data row1 col2\" >861.0919</td>\n",
       "      <td id=\"T_18137_row1_col3\" class=\"data row1 col3\" >29.3421</td>\n",
       "      <td id=\"T_18137_row1_col4\" class=\"data row1 col4\" >0.0427</td>\n",
       "      <td id=\"T_18137_row1_col5\" class=\"data row1 col5\" >0.3132</td>\n",
       "      <td id=\"T_18137_row1_col6\" class=\"data row1 col6\" >0.2942</td>\n",
       "      <td id=\"T_18137_row1_col7\" class=\"data row1 col7\" >0.1420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_18137_level0_row2\" class=\"row_heading level0 row2\" >lightgbm</th>\n",
       "      <td id=\"T_18137_row2_col0\" class=\"data row2 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_18137_row2_col1\" class=\"data row2 col1\" >25.2541</td>\n",
       "      <td id=\"T_18137_row2_col2\" class=\"data row2 col2\" >868.2889</td>\n",
       "      <td id=\"T_18137_row2_col3\" class=\"data row2 col3\" >29.4634</td>\n",
       "      <td id=\"T_18137_row2_col4\" class=\"data row2 col4\" >0.0348</td>\n",
       "      <td id=\"T_18137_row2_col5\" class=\"data row2 col5\" >0.3141</td>\n",
       "      <td id=\"T_18137_row2_col6\" class=\"data row2 col6\" >0.2919</td>\n",
       "      <td id=\"T_18137_row2_col7\" class=\"data row2 col7\" >0.4010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_18137_level0_row3\" class=\"row_heading level0 row3\" >rf</th>\n",
       "      <td id=\"T_18137_row3_col0\" class=\"data row3 col0\" >Random Forest Regressor</td>\n",
       "      <td id=\"T_18137_row3_col1\" class=\"data row3 col1\" >25.2684</td>\n",
       "      <td id=\"T_18137_row3_col2\" class=\"data row3 col2\" >875.0625</td>\n",
       "      <td id=\"T_18137_row3_col3\" class=\"data row3 col3\" >29.5774</td>\n",
       "      <td id=\"T_18137_row3_col4\" class=\"data row3 col4\" >0.0273</td>\n",
       "      <td id=\"T_18137_row3_col5\" class=\"data row3 col5\" >0.3148</td>\n",
       "      <td id=\"T_18137_row3_col6\" class=\"data row3 col6\" >0.2913</td>\n",
       "      <td id=\"T_18137_row3_col7\" class=\"data row3 col7\" >4.5540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_18137_level0_row4\" class=\"row_heading level0 row4\" >lr</th>\n",
       "      <td id=\"T_18137_row4_col0\" class=\"data row4 col0\" >Linear Regression</td>\n",
       "      <td id=\"T_18137_row4_col1\" class=\"data row4 col1\" >25.5159</td>\n",
       "      <td id=\"T_18137_row4_col2\" class=\"data row4 col2\" >879.3566</td>\n",
       "      <td id=\"T_18137_row4_col3\" class=\"data row4 col3\" >29.6515</td>\n",
       "      <td id=\"T_18137_row4_col4\" class=\"data row4 col4\" >0.0223</td>\n",
       "      <td id=\"T_18137_row4_col5\" class=\"data row4 col5\" >0.3169</td>\n",
       "      <td id=\"T_18137_row4_col6\" class=\"data row4 col6\" >0.2963</td>\n",
       "      <td id=\"T_18137_row4_col7\" class=\"data row4 col7\" >0.0320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_18137_level0_row5\" class=\"row_heading level0 row5\" >ridge</th>\n",
       "      <td id=\"T_18137_row5_col0\" class=\"data row5 col0\" >Ridge Regression</td>\n",
       "      <td id=\"T_18137_row5_col1\" class=\"data row5 col1\" >25.5158</td>\n",
       "      <td id=\"T_18137_row5_col2\" class=\"data row5 col2\" >879.3586</td>\n",
       "      <td id=\"T_18137_row5_col3\" class=\"data row5 col3\" >29.6515</td>\n",
       "      <td id=\"T_18137_row5_col4\" class=\"data row5 col4\" >0.0223</td>\n",
       "      <td id=\"T_18137_row5_col5\" class=\"data row5 col5\" >0.3169</td>\n",
       "      <td id=\"T_18137_row5_col6\" class=\"data row5 col6\" >0.2962</td>\n",
       "      <td id=\"T_18137_row5_col7\" class=\"data row5 col7\" >0.0300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_18137_level0_row6\" class=\"row_heading level0 row6\" >br</th>\n",
       "      <td id=\"T_18137_row6_col0\" class=\"data row6 col0\" >Bayesian Ridge</td>\n",
       "      <td id=\"T_18137_row6_col1\" class=\"data row6 col1\" >25.5155</td>\n",
       "      <td id=\"T_18137_row6_col2\" class=\"data row6 col2\" >879.5207</td>\n",
       "      <td id=\"T_18137_row6_col3\" class=\"data row6 col3\" >29.6542</td>\n",
       "      <td id=\"T_18137_row6_col4\" class=\"data row6 col4\" >0.0222</td>\n",
       "      <td id=\"T_18137_row6_col5\" class=\"data row6 col5\" >0.3170</td>\n",
       "      <td id=\"T_18137_row6_col6\" class=\"data row6 col6\" >0.2963</td>\n",
       "      <td id=\"T_18137_row6_col7\" class=\"data row6 col7\" >0.0370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_18137_level0_row7\" class=\"row_heading level0 row7\" >lar</th>\n",
       "      <td id=\"T_18137_row7_col0\" class=\"data row7 col0\" >Least Angle Regression</td>\n",
       "      <td id=\"T_18137_row7_col1\" class=\"data row7 col1\" >25.5209</td>\n",
       "      <td id=\"T_18137_row7_col2\" class=\"data row7 col2\" >879.6177</td>\n",
       "      <td id=\"T_18137_row7_col3\" class=\"data row7 col3\" >29.6559</td>\n",
       "      <td id=\"T_18137_row7_col4\" class=\"data row7 col4\" >0.0220</td>\n",
       "      <td id=\"T_18137_row7_col5\" class=\"data row7 col5\" >0.3170</td>\n",
       "      <td id=\"T_18137_row7_col6\" class=\"data row7 col6\" >0.2963</td>\n",
       "      <td id=\"T_18137_row7_col7\" class=\"data row7 col7\" >0.0300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_18137_level0_row8\" class=\"row_heading level0 row8\" >lasso</th>\n",
       "      <td id=\"T_18137_row8_col0\" class=\"data row8 col0\" >Lasso Regression</td>\n",
       "      <td id=\"T_18137_row8_col1\" class=\"data row8 col1\" >25.6477</td>\n",
       "      <td id=\"T_18137_row8_col2\" class=\"data row8 col2\" >884.3585</td>\n",
       "      <td id=\"T_18137_row8_col3\" class=\"data row8 col3\" >29.7356</td>\n",
       "      <td id=\"T_18137_row8_col4\" class=\"data row8 col4\" >0.0169</td>\n",
       "      <td id=\"T_18137_row8_col5\" class=\"data row8 col5\" >0.3181</td>\n",
       "      <td id=\"T_18137_row8_col6\" class=\"data row8 col6\" >0.2981</td>\n",
       "      <td id=\"T_18137_row8_col7\" class=\"data row8 col7\" >0.0290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_18137_level0_row9\" class=\"row_heading level0 row9\" >llar</th>\n",
       "      <td id=\"T_18137_row9_col0\" class=\"data row9 col0\" >Lasso Least Angle Regression</td>\n",
       "      <td id=\"T_18137_row9_col1\" class=\"data row9 col1\" >25.6477</td>\n",
       "      <td id=\"T_18137_row9_col2\" class=\"data row9 col2\" >884.3585</td>\n",
       "      <td id=\"T_18137_row9_col3\" class=\"data row9 col3\" >29.7356</td>\n",
       "      <td id=\"T_18137_row9_col4\" class=\"data row9 col4\" >0.0169</td>\n",
       "      <td id=\"T_18137_row9_col5\" class=\"data row9 col5\" >0.3181</td>\n",
       "      <td id=\"T_18137_row9_col6\" class=\"data row9 col6\" >0.2981</td>\n",
       "      <td id=\"T_18137_row9_col7\" class=\"data row9 col7\" >0.0320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_18137_level0_row10\" class=\"row_heading level0 row10\" >en</th>\n",
       "      <td id=\"T_18137_row10_col0\" class=\"data row10 col0\" >Elastic Net</td>\n",
       "      <td id=\"T_18137_row10_col1\" class=\"data row10 col1\" >25.6778</td>\n",
       "      <td id=\"T_18137_row10_col2\" class=\"data row10 col2\" >886.3746</td>\n",
       "      <td id=\"T_18137_row10_col3\" class=\"data row10 col3\" >29.7694</td>\n",
       "      <td id=\"T_18137_row10_col4\" class=\"data row10 col4\" >0.0146</td>\n",
       "      <td id=\"T_18137_row10_col5\" class=\"data row10 col5\" >0.3185</td>\n",
       "      <td id=\"T_18137_row10_col6\" class=\"data row10 col6\" >0.2985</td>\n",
       "      <td id=\"T_18137_row10_col7\" class=\"data row10 col7\" >0.0310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_18137_level0_row11\" class=\"row_heading level0 row11\" >omp</th>\n",
       "      <td id=\"T_18137_row11_col0\" class=\"data row11 col0\" >Orthogonal Matching Pursuit</td>\n",
       "      <td id=\"T_18137_row11_col1\" class=\"data row11 col1\" >25.8559</td>\n",
       "      <td id=\"T_18137_row11_col2\" class=\"data row11 col2\" >896.6072</td>\n",
       "      <td id=\"T_18137_row11_col3\" class=\"data row11 col3\" >29.9405</td>\n",
       "      <td id=\"T_18137_row11_col4\" class=\"data row11 col4\" >0.0033</td>\n",
       "      <td id=\"T_18137_row11_col5\" class=\"data row11 col5\" >0.3203</td>\n",
       "      <td id=\"T_18137_row11_col6\" class=\"data row11 col6\" >0.3007</td>\n",
       "      <td id=\"T_18137_row11_col7\" class=\"data row11 col7\" >0.0310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_18137_level0_row12\" class=\"row_heading level0 row12\" >dummy</th>\n",
       "      <td id=\"T_18137_row12_col0\" class=\"data row12 col0\" >Dummy Regressor</td>\n",
       "      <td id=\"T_18137_row12_col1\" class=\"data row12 col1\" >26.0064</td>\n",
       "      <td id=\"T_18137_row12_col2\" class=\"data row12 col2\" >900.1565</td>\n",
       "      <td id=\"T_18137_row12_col3\" class=\"data row12 col3\" >29.9999</td>\n",
       "      <td id=\"T_18137_row12_col4\" class=\"data row12 col4\" >-0.0007</td>\n",
       "      <td id=\"T_18137_row12_col5\" class=\"data row12 col5\" >0.3209</td>\n",
       "      <td id=\"T_18137_row12_col6\" class=\"data row12 col6\" >0.3022</td>\n",
       "      <td id=\"T_18137_row12_col7\" class=\"data row12 col7\" >0.0290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_18137_level0_row13\" class=\"row_heading level0 row13\" >et</th>\n",
       "      <td id=\"T_18137_row13_col0\" class=\"data row13 col0\" >Extra Trees Regressor</td>\n",
       "      <td id=\"T_18137_row13_col1\" class=\"data row13 col1\" >25.4236</td>\n",
       "      <td id=\"T_18137_row13_col2\" class=\"data row13 col2\" >908.0145</td>\n",
       "      <td id=\"T_18137_row13_col3\" class=\"data row13 col3\" >30.1287</td>\n",
       "      <td id=\"T_18137_row13_col4\" class=\"data row13 col4\" >-0.0094</td>\n",
       "      <td id=\"T_18137_row13_col5\" class=\"data row13 col5\" >0.3202</td>\n",
       "      <td id=\"T_18137_row13_col6\" class=\"data row13 col6\" >0.2930</td>\n",
       "      <td id=\"T_18137_row13_col7\" class=\"data row13 col7\" >2.7100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_18137_level0_row14\" class=\"row_heading level0 row14\" >xgboost</th>\n",
       "      <td id=\"T_18137_row14_col0\" class=\"data row14 col0\" >Extreme Gradient Boosting</td>\n",
       "      <td id=\"T_18137_row14_col1\" class=\"data row14 col1\" >26.2609</td>\n",
       "      <td id=\"T_18137_row14_col2\" class=\"data row14 col2\" >970.3372</td>\n",
       "      <td id=\"T_18137_row14_col3\" class=\"data row14 col3\" >31.1468</td>\n",
       "      <td id=\"T_18137_row14_col4\" class=\"data row14 col4\" >-0.0790</td>\n",
       "      <td id=\"T_18137_row14_col5\" class=\"data row14 col5\" >0.3299</td>\n",
       "      <td id=\"T_18137_row14_col6\" class=\"data row14 col6\" >0.3015</td>\n",
       "      <td id=\"T_18137_row14_col7\" class=\"data row14 col7\" >0.2230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_18137_level0_row15\" class=\"row_heading level0 row15\" >knn</th>\n",
       "      <td id=\"T_18137_row15_col0\" class=\"data row15 col0\" >K Neighbors Regressor</td>\n",
       "      <td id=\"T_18137_row15_col1\" class=\"data row15 col1\" >26.6735</td>\n",
       "      <td id=\"T_18137_row15_col2\" class=\"data row15 col2\" >1016.7014</td>\n",
       "      <td id=\"T_18137_row15_col3\" class=\"data row15 col3\" >31.8778</td>\n",
       "      <td id=\"T_18137_row15_col4\" class=\"data row15 col4\" >-0.1303</td>\n",
       "      <td id=\"T_18137_row15_col5\" class=\"data row15 col5\" >0.3367</td>\n",
       "      <td id=\"T_18137_row15_col6\" class=\"data row15 col6\" >0.3057</td>\n",
       "      <td id=\"T_18137_row15_col7\" class=\"data row15 col7\" >0.0700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_18137_level0_row16\" class=\"row_heading level0 row16\" >huber</th>\n",
       "      <td id=\"T_18137_row16_col0\" class=\"data row16 col0\" >Huber Regressor</td>\n",
       "      <td id=\"T_18137_row16_col1\" class=\"data row16 col1\" >28.7072</td>\n",
       "      <td id=\"T_18137_row16_col2\" class=\"data row16 col2\" >1164.3754</td>\n",
       "      <td id=\"T_18137_row16_col3\" class=\"data row16 col3\" >34.1209</td>\n",
       "      <td id=\"T_18137_row16_col4\" class=\"data row16 col4\" >-0.2952</td>\n",
       "      <td id=\"T_18137_row16_col5\" class=\"data row16 col5\" >0.3581</td>\n",
       "      <td id=\"T_18137_row16_col6\" class=\"data row16 col6\" >0.3229</td>\n",
       "      <td id=\"T_18137_row16_col7\" class=\"data row16 col7\" >0.1300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_18137_level0_row17\" class=\"row_heading level0 row17\" >dt</th>\n",
       "      <td id=\"T_18137_row17_col0\" class=\"data row17 col0\" >Decision Tree Regressor</td>\n",
       "      <td id=\"T_18137_row17_col1\" class=\"data row17 col1\" >32.5845</td>\n",
       "      <td id=\"T_18137_row17_col2\" class=\"data row17 col2\" >1703.0839</td>\n",
       "      <td id=\"T_18137_row17_col3\" class=\"data row17 col3\" >41.2551</td>\n",
       "      <td id=\"T_18137_row17_col4\" class=\"data row17 col4\" >-0.8931</td>\n",
       "      <td id=\"T_18137_row17_col5\" class=\"data row17 col5\" >0.4356</td>\n",
       "      <td id=\"T_18137_row17_col6\" class=\"data row17 col6\" >0.3676</td>\n",
       "      <td id=\"T_18137_row17_col7\" class=\"data row17 col7\" >0.1460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_18137_level0_row18\" class=\"row_heading level0 row18\" >par</th>\n",
       "      <td id=\"T_18137_row18_col0\" class=\"data row18 col0\" >Passive Aggressive Regressor</td>\n",
       "      <td id=\"T_18137_row18_col1\" class=\"data row18 col1\" >41.3053</td>\n",
       "      <td id=\"T_18137_row18_col2\" class=\"data row18 col2\" >2549.0839</td>\n",
       "      <td id=\"T_18137_row18_col3\" class=\"data row18 col3\" >49.5572</td>\n",
       "      <td id=\"T_18137_row18_col4\" class=\"data row18 col4\" >-1.8497</td>\n",
       "      <td id=\"T_18137_row18_col5\" class=\"data row18 col5\" >0.5458</td>\n",
       "      <td id=\"T_18137_row18_col6\" class=\"data row18 col6\" >0.4443</td>\n",
       "      <td id=\"T_18137_row18_col7\" class=\"data row18 col7\" >0.0390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7b8d56806ce0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c67d6f583a44d0f9e683b4000a20690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "colab": {
        "custom_widget_manager": {
         "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/b3e629b1971e1542/manager.min.js"
        }
       }
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model=compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "9X58JQLBCFz2"
   },
   "outputs": [],
   "source": [
    "#auto ml ile sonuÃ§ Ã§Ä±kmadÄ±\n",
    "#deep learning ile deneyelim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wWZ2BUaIOUbL",
    "outputId": "3ee52d8f-8474-4de5-d6bd-565cb44a895f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.60.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.17.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "JnxIbVdEOYTH"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "s8wkWxIAOcrF"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "fyyXN-KwOe9Q"
   },
   "outputs": [],
   "source": [
    "x=df.drop('cost', axis=1)\n",
    "y=df[[\"cost\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "xtIimTIyO2mc"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "iYVD7o2vO2pA"
   },
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "lsuyIiJDOlC1"
   },
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(1))   #regression olduÄŸu iÃ§in sadece Dense(1) yazdÄ±k. Tek bir deÄŸer tahmin edeceÄŸiz\n",
    "model.compile(loss='mse', optimizer='adam')  #mes mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "33YMY07XOtx5",
    "outputId": "ec7d556d-0290-45f9-ff2e-f69de06fbc8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "84/84 [==============================] - 4s 6ms/step - loss: 4174.4019 - val_loss: 1277.6294\n",
      "Epoch 2/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1339.8447 - val_loss: 1247.6162\n",
      "Epoch 3/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1340.4447 - val_loss: 1270.6266\n",
      "Epoch 4/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1334.6183 - val_loss: 1246.4099\n",
      "Epoch 5/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1330.3323 - val_loss: 1247.8762\n",
      "Epoch 6/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1325.3173 - val_loss: 1264.1691\n",
      "Epoch 7/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1338.5968 - val_loss: 1287.4020\n",
      "Epoch 8/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1342.8949 - val_loss: 1500.5619\n",
      "Epoch 9/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1340.6003 - val_loss: 1245.5553\n",
      "Epoch 10/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1353.4741 - val_loss: 1250.3984\n",
      "Epoch 11/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1370.9686 - val_loss: 1267.8605\n",
      "Epoch 12/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1321.6442 - val_loss: 1271.7100\n",
      "Epoch 13/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1376.3385 - val_loss: 1268.8815\n",
      "Epoch 14/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1321.6821 - val_loss: 1264.5140\n",
      "Epoch 15/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1332.3873 - val_loss: 1226.2584\n",
      "Epoch 16/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1318.1700 - val_loss: 1280.7891\n",
      "Epoch 17/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1390.9166 - val_loss: 1304.7411\n",
      "Epoch 18/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1338.9131 - val_loss: 1234.9637\n",
      "Epoch 19/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1317.2899 - val_loss: 1259.5347\n",
      "Epoch 20/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1310.1704 - val_loss: 1348.3698\n",
      "Epoch 21/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 1367.5514 - val_loss: 1223.5623\n",
      "Epoch 22/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1303.6003 - val_loss: 1218.3529\n",
      "Epoch 23/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1330.7186 - val_loss: 1228.9250\n",
      "Epoch 24/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1318.4705 - val_loss: 1317.2605\n",
      "Epoch 25/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1316.3528 - val_loss: 1211.2845\n",
      "Epoch 26/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1304.6667 - val_loss: 1255.4156\n",
      "Epoch 27/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1324.2830 - val_loss: 1203.9875\n",
      "Epoch 28/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1309.0958 - val_loss: 1327.0082\n",
      "Epoch 29/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1321.5491 - val_loss: 1262.6560\n",
      "Epoch 30/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1328.9360 - val_loss: 1222.9927\n",
      "Epoch 31/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1306.9341 - val_loss: 1203.4303\n",
      "Epoch 32/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1323.1526 - val_loss: 1199.9542\n",
      "Epoch 33/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1288.4277 - val_loss: 1251.9697\n",
      "Epoch 34/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1290.9459 - val_loss: 1255.4946\n",
      "Epoch 35/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1346.4161 - val_loss: 1218.2329\n",
      "Epoch 36/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1282.5916 - val_loss: 1192.0498\n",
      "Epoch 37/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 1287.0835 - val_loss: 1190.4135\n",
      "Epoch 38/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 1275.1204 - val_loss: 1192.3181\n",
      "Epoch 39/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1272.1440 - val_loss: 1203.4214\n",
      "Epoch 40/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1269.7777 - val_loss: 1213.1936\n",
      "Epoch 41/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1273.2069 - val_loss: 1177.7570\n",
      "Epoch 42/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 1286.5734 - val_loss: 1195.9301\n",
      "Epoch 43/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 1265.2159 - val_loss: 1232.2312\n",
      "Epoch 44/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 1274.2242 - val_loss: 1171.1257\n",
      "Epoch 45/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 1280.1609 - val_loss: 1246.6296\n",
      "Epoch 46/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1268.5940 - val_loss: 1165.4786\n",
      "Epoch 47/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1261.0830 - val_loss: 1178.2864\n",
      "Epoch 48/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1255.5127 - val_loss: 1192.3087\n",
      "Epoch 49/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 1262.7394 - val_loss: 1212.4480\n",
      "Epoch 50/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1261.6809 - val_loss: 1173.7085\n",
      "Epoch 51/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1265.8171 - val_loss: 1476.2594\n",
      "Epoch 52/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1277.3140 - val_loss: 1238.2106\n",
      "Epoch 53/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1250.4866 - val_loss: 1155.1370\n",
      "Epoch 54/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1227.4882 - val_loss: 1149.4688\n",
      "Epoch 55/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1234.9620 - val_loss: 1166.5070\n",
      "Epoch 56/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1243.3734 - val_loss: 1211.5204\n",
      "Epoch 57/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1246.8685 - val_loss: 1266.7072\n",
      "Epoch 58/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1234.2012 - val_loss: 1169.1246\n",
      "Epoch 59/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1226.7340 - val_loss: 1133.6490\n",
      "Epoch 60/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1219.2823 - val_loss: 1161.0714\n",
      "Epoch 61/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1204.3229 - val_loss: 1127.3889\n",
      "Epoch 62/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1216.5210 - val_loss: 1125.3273\n",
      "Epoch 63/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1222.6357 - val_loss: 1335.1523\n",
      "Epoch 64/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1208.1223 - val_loss: 1133.4004\n",
      "Epoch 65/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1190.8844 - val_loss: 1196.8029\n",
      "Epoch 66/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1202.6979 - val_loss: 1114.9902\n",
      "Epoch 67/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1208.8392 - val_loss: 1121.7196\n",
      "Epoch 68/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1202.8126 - val_loss: 1108.6270\n",
      "Epoch 69/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1225.5223 - val_loss: 1320.4818\n",
      "Epoch 70/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1178.8795 - val_loss: 1165.3029\n",
      "Epoch 71/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1173.9297 - val_loss: 1100.5018\n",
      "Epoch 72/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1204.7354 - val_loss: 1592.1252\n",
      "Epoch 73/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1190.3875 - val_loss: 1094.4418\n",
      "Epoch 74/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1156.1583 - val_loss: 1154.2101\n",
      "Epoch 75/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1179.1185 - val_loss: 1094.9286\n",
      "Epoch 76/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1172.9001 - val_loss: 1088.2277\n",
      "Epoch 77/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1169.0934 - val_loss: 1244.2181\n",
      "Epoch 78/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1157.1400 - val_loss: 1082.5935\n",
      "Epoch 79/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1181.1584 - val_loss: 1080.3102\n",
      "Epoch 80/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1158.7393 - val_loss: 1114.0044\n",
      "Epoch 81/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1128.9026 - val_loss: 1075.7938\n",
      "Epoch 82/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1130.6591 - val_loss: 1075.7191\n",
      "Epoch 83/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1134.8427 - val_loss: 1069.7919\n",
      "Epoch 84/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1150.3419 - val_loss: 1102.4612\n",
      "Epoch 85/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1126.1584 - val_loss: 1102.9723\n",
      "Epoch 86/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1117.0677 - val_loss: 1066.9067\n",
      "Epoch 87/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1153.5989 - val_loss: 1063.1433\n",
      "Epoch 88/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 1136.8287 - val_loss: 1160.1006\n",
      "Epoch 89/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 1115.5695 - val_loss: 1103.9371\n",
      "Epoch 90/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 1123.6775 - val_loss: 1288.2144\n",
      "Epoch 91/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 1174.8735 - val_loss: 1355.9504\n",
      "Epoch 92/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 1157.6082 - val_loss: 1067.9099\n",
      "Epoch 93/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1169.8513 - val_loss: 1071.8461\n",
      "Epoch 94/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 1114.1093 - val_loss: 1076.4539\n",
      "Epoch 95/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 1094.5704 - val_loss: 1079.7653\n",
      "Epoch 96/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1129.0475 - val_loss: 1140.2289\n",
      "Epoch 97/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 1123.4796 - val_loss: 1052.1848\n",
      "Epoch 98/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1102.1198 - val_loss: 1093.7736\n",
      "Epoch 99/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 1129.7114 - val_loss: 1104.5472\n",
      "Epoch 100/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 1118.7833 - val_loss: 1059.6886\n",
      "Epoch 101/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1105.8401 - val_loss: 1048.8201\n",
      "Epoch 102/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1136.5942 - val_loss: 1235.3834\n",
      "Epoch 103/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1098.5315 - val_loss: 1064.7106\n",
      "Epoch 104/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1085.3444 - val_loss: 1105.2379\n",
      "Epoch 105/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1104.3303 - val_loss: 1164.7585\n",
      "Epoch 106/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1106.2874 - val_loss: 1068.1384\n",
      "Epoch 107/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1103.9106 - val_loss: 1065.1880\n",
      "Epoch 108/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1104.8835 - val_loss: 1043.5035\n",
      "Epoch 109/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1122.2050 - val_loss: 1046.5166\n",
      "Epoch 110/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1098.0107 - val_loss: 1042.1255\n",
      "Epoch 111/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1109.5776 - val_loss: 1355.3158\n",
      "Epoch 112/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1095.8711 - val_loss: 1040.5201\n",
      "Epoch 113/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1081.6451 - val_loss: 1038.7687\n",
      "Epoch 114/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1093.6353 - val_loss: 1214.5236\n",
      "Epoch 115/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1107.1564 - val_loss: 1092.2471\n",
      "Epoch 116/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1091.7159 - val_loss: 1034.3142\n",
      "Epoch 117/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1102.1403 - val_loss: 1038.0687\n",
      "Epoch 118/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1084.6145 - val_loss: 1049.3477\n",
      "Epoch 119/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1102.4364 - val_loss: 1034.4686\n",
      "Epoch 120/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1074.0959 - val_loss: 1047.2976\n",
      "Epoch 121/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1100.9073 - val_loss: 1034.0822\n",
      "Epoch 122/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1081.5413 - val_loss: 1191.7347\n",
      "Epoch 123/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1076.1478 - val_loss: 1106.4194\n",
      "Epoch 124/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1094.1965 - val_loss: 1034.6508\n",
      "Epoch 125/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1105.5697 - val_loss: 1030.9957\n",
      "Epoch 126/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1078.1498 - val_loss: 1032.3448\n",
      "Epoch 127/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1093.2902 - val_loss: 1109.5004\n",
      "Epoch 128/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1114.3353 - val_loss: 1031.8124\n",
      "Epoch 129/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1077.3427 - val_loss: 1028.3235\n",
      "Epoch 130/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1064.5082 - val_loss: 1050.5046\n",
      "Epoch 131/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1085.2833 - val_loss: 1033.1775\n",
      "Epoch 132/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1054.5344 - val_loss: 1118.9001\n",
      "Epoch 133/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1064.1549 - val_loss: 1081.6719\n",
      "Epoch 134/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1077.3988 - val_loss: 1050.4872\n",
      "Epoch 135/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1072.2622 - val_loss: 1026.3457\n",
      "Epoch 136/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1067.3104 - val_loss: 1143.2070\n",
      "Epoch 137/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1083.7692 - val_loss: 1030.6453\n",
      "Epoch 138/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1049.5294 - val_loss: 1083.2356\n",
      "Epoch 139/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1064.6224 - val_loss: 1019.4792\n",
      "Epoch 140/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1063.5792 - val_loss: 1070.0565\n",
      "Epoch 141/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 1059.1321 - val_loss: 1049.7429\n",
      "Epoch 142/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1056.3601 - val_loss: 1014.3229\n",
      "Epoch 143/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1056.9009 - val_loss: 1135.2740\n",
      "Epoch 144/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 1089.6915 - val_loss: 1176.8340\n",
      "Epoch 145/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 1095.1362 - val_loss: 1035.9119\n",
      "Epoch 146/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 1059.7294 - val_loss: 1074.7281\n",
      "Epoch 147/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 1054.7432 - val_loss: 1018.4036\n",
      "Epoch 148/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 1074.0864 - val_loss: 1058.5834\n",
      "Epoch 149/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 1056.0955 - val_loss: 1067.1786\n",
      "Epoch 150/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1067.2800 - val_loss: 1079.7588\n",
      "Epoch 151/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 1071.2412 - val_loss: 1035.4247\n",
      "Epoch 152/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 1044.0824 - val_loss: 1028.2605\n",
      "Epoch 153/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 1056.0510 - val_loss: 1044.0682\n",
      "Epoch 154/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1044.6940 - val_loss: 1018.6057\n",
      "Epoch 155/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1055.7991 - val_loss: 1040.5930\n",
      "Epoch 156/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1053.1334 - val_loss: 1011.2772\n",
      "Epoch 157/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1038.0609 - val_loss: 1051.0947\n",
      "Epoch 158/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1046.4451 - val_loss: 1009.9954\n",
      "Epoch 159/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1034.8873 - val_loss: 1011.5589\n",
      "Epoch 160/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1042.0543 - val_loss: 1034.6746\n",
      "Epoch 161/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1065.1852 - val_loss: 1008.2677\n",
      "Epoch 162/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1028.9550 - val_loss: 1010.5981\n",
      "Epoch 163/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1033.3593 - val_loss: 1015.6194\n",
      "Epoch 164/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1049.8893 - val_loss: 1086.1046\n",
      "Epoch 165/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1036.4508 - val_loss: 1004.7256\n",
      "Epoch 166/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1047.3140 - val_loss: 1001.6237\n",
      "Epoch 167/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1041.4856 - val_loss: 1001.5482\n",
      "Epoch 168/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1045.4136 - val_loss: 1292.6661\n",
      "Epoch 169/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1046.7539 - val_loss: 1001.9509\n",
      "Epoch 170/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1051.4055 - val_loss: 1002.3177\n",
      "Epoch 171/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 1031.4845 - val_loss: 1007.7788\n",
      "Epoch 172/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1038.2675 - val_loss: 1007.2653\n",
      "Epoch 173/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1051.2100 - val_loss: 1063.2943\n",
      "Epoch 174/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1034.5763 - val_loss: 1013.5086\n",
      "Epoch 175/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1036.0057 - val_loss: 1001.7486\n",
      "Epoch 176/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1044.8209 - val_loss: 1006.8032\n",
      "Epoch 177/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1039.5818 - val_loss: 999.4282\n",
      "Epoch 178/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1022.3767 - val_loss: 1035.5214\n",
      "Epoch 179/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1044.3375 - val_loss: 1035.6826\n",
      "Epoch 180/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1031.2124 - val_loss: 999.0488\n",
      "Epoch 181/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1016.3663 - val_loss: 1009.7474\n",
      "Epoch 182/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1016.9173 - val_loss: 995.1787\n",
      "Epoch 183/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1017.2821 - val_loss: 1023.7869\n",
      "Epoch 184/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1014.6551 - val_loss: 1019.0127\n",
      "Epoch 185/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1023.3834 - val_loss: 1073.0341\n",
      "Epoch 186/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1032.3712 - val_loss: 1149.8254\n",
      "Epoch 187/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1006.9731 - val_loss: 1025.1019\n",
      "Epoch 188/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1008.3479 - val_loss: 998.5988\n",
      "Epoch 189/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1011.5673 - val_loss: 991.4254\n",
      "Epoch 190/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 1021.6050 - val_loss: 1004.4644\n",
      "Epoch 191/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 1010.9553 - val_loss: 1035.7484\n",
      "Epoch 192/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1012.1426 - val_loss: 1018.3737\n",
      "Epoch 193/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 1003.0565 - val_loss: 1068.5970\n",
      "Epoch 194/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 1004.3571 - val_loss: 990.4920\n",
      "Epoch 195/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1002.8831 - val_loss: 990.4762\n",
      "Epoch 196/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 999.4463 - val_loss: 989.4316\n",
      "Epoch 197/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 1014.7770 - val_loss: 1011.3752\n",
      "Epoch 198/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 1008.2964 - val_loss: 994.6071\n",
      "Epoch 199/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1023.4107 - val_loss: 1011.4778\n",
      "Epoch 200/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 993.8185 - val_loss: 982.0090\n",
      "Epoch 201/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 1007.0328 - val_loss: 1111.9023\n",
      "Epoch 202/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 1009.7556 - val_loss: 990.5651\n",
      "Epoch 203/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1002.6029 - val_loss: 1017.7051\n",
      "Epoch 204/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1002.3996 - val_loss: 975.2955\n",
      "Epoch 205/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 994.1167 - val_loss: 980.6661\n",
      "Epoch 206/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1026.5837 - val_loss: 1122.5503\n",
      "Epoch 207/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 996.2847 - val_loss: 1114.6566\n",
      "Epoch 208/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1002.9272 - val_loss: 989.6891\n",
      "Epoch 209/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1028.9264 - val_loss: 985.0836\n",
      "Epoch 210/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1010.0482 - val_loss: 973.8456\n",
      "Epoch 211/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 984.3461 - val_loss: 983.5107\n",
      "Epoch 212/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 986.4265 - val_loss: 970.7092\n",
      "Epoch 213/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 989.2677 - val_loss: 969.6953\n",
      "Epoch 214/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 992.8339 - val_loss: 992.0266\n",
      "Epoch 215/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 994.1984 - val_loss: 990.3907\n",
      "Epoch 216/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 999.3555 - val_loss: 979.5720\n",
      "Epoch 217/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 986.8073 - val_loss: 966.2717\n",
      "Epoch 218/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 994.2442 - val_loss: 989.2701\n",
      "Epoch 219/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1001.5431 - val_loss: 964.2147\n",
      "Epoch 220/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 981.4703 - val_loss: 971.7321\n",
      "Epoch 221/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 979.6360 - val_loss: 964.5401\n",
      "Epoch 222/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 991.2153 - val_loss: 964.9156\n",
      "Epoch 223/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 984.7855 - val_loss: 969.9211\n",
      "Epoch 224/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 994.6385 - val_loss: 979.0439\n",
      "Epoch 225/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 968.3621 - val_loss: 978.2480\n",
      "Epoch 226/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 974.9683 - val_loss: 966.7870\n",
      "Epoch 227/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 970.1567 - val_loss: 967.2885\n",
      "Epoch 228/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 984.8672 - val_loss: 1002.1899\n",
      "Epoch 229/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 968.1284 - val_loss: 966.3519\n",
      "Epoch 230/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 988.7864 - val_loss: 979.2383\n",
      "Epoch 231/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 968.8359 - val_loss: 960.9400\n",
      "Epoch 232/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 980.4095 - val_loss: 965.2327\n",
      "Epoch 233/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 976.2344 - val_loss: 946.3682\n",
      "Epoch 234/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 983.4454 - val_loss: 959.9382\n",
      "Epoch 235/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 958.8152 - val_loss: 958.2208\n",
      "Epoch 236/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 966.3719 - val_loss: 953.6941\n",
      "Epoch 237/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 978.5870 - val_loss: 944.5264\n",
      "Epoch 238/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 955.7184 - val_loss: 946.8682\n",
      "Epoch 239/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 959.8397 - val_loss: 976.7851\n",
      "Epoch 240/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 989.1333 - val_loss: 961.0801\n",
      "Epoch 241/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 987.3109 - val_loss: 1033.3823\n",
      "Epoch 242/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 963.2225 - val_loss: 939.2077\n",
      "Epoch 243/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 976.2129 - val_loss: 946.8878\n",
      "Epoch 244/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 957.2892 - val_loss: 963.6619\n",
      "Epoch 245/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 951.5983 - val_loss: 939.3793\n",
      "Epoch 246/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 944.5472 - val_loss: 947.1037\n",
      "Epoch 247/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 956.7095 - val_loss: 939.3204\n",
      "Epoch 248/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 939.7151 - val_loss: 958.8418\n",
      "Epoch 249/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 957.1661 - val_loss: 932.5469\n",
      "Epoch 250/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 948.7094 - val_loss: 942.7781\n",
      "Epoch 251/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 980.7277 - val_loss: 974.8723\n",
      "Epoch 252/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 942.0830 - val_loss: 932.3627\n",
      "Epoch 253/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 940.5104 - val_loss: 955.8384\n",
      "Epoch 254/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 955.7226 - val_loss: 942.0341\n",
      "Epoch 255/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 938.5203 - val_loss: 940.3578\n",
      "Epoch 256/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 945.2510 - val_loss: 926.5441\n",
      "Epoch 257/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 939.5836 - val_loss: 926.6521\n",
      "Epoch 258/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 940.9772 - val_loss: 959.9511\n",
      "Epoch 259/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 943.3655 - val_loss: 929.5185\n",
      "Epoch 260/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 928.4576 - val_loss: 925.7814\n",
      "Epoch 261/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 935.9635 - val_loss: 923.0821\n",
      "Epoch 262/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 970.8633 - val_loss: 946.3269\n",
      "Epoch 263/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 943.8365 - val_loss: 921.2650\n",
      "Epoch 264/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 928.7021 - val_loss: 919.8717\n",
      "Epoch 265/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 934.2437 - val_loss: 922.6840\n",
      "Epoch 266/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 931.9319 - val_loss: 937.7134\n",
      "Epoch 267/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 927.9124 - val_loss: 934.8061\n",
      "Epoch 268/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 927.6452 - val_loss: 920.9622\n",
      "Epoch 269/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 924.1284 - val_loss: 917.2408\n",
      "Epoch 270/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 921.9660 - val_loss: 927.6727\n",
      "Epoch 271/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 936.5717 - val_loss: 908.5449\n",
      "Epoch 272/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 918.7083 - val_loss: 906.5293\n",
      "Epoch 273/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 912.2147 - val_loss: 910.0991\n",
      "Epoch 274/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 913.9612 - val_loss: 904.6253\n",
      "Epoch 275/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 916.4608 - val_loss: 911.1390\n",
      "Epoch 276/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 909.0827 - val_loss: 912.1962\n",
      "Epoch 277/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 910.0416 - val_loss: 910.4193\n",
      "Epoch 278/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 910.8528 - val_loss: 901.1387\n",
      "Epoch 279/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 914.0711 - val_loss: 921.4995\n",
      "Epoch 280/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 901.7836 - val_loss: 898.7997\n",
      "Epoch 281/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 911.8234 - val_loss: 907.1702\n",
      "Epoch 282/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 915.8986 - val_loss: 923.9938\n",
      "Epoch 283/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 922.1595 - val_loss: 895.8525\n",
      "Epoch 284/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 915.5387 - val_loss: 901.0997\n",
      "Epoch 285/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 910.4578 - val_loss: 895.3142\n",
      "Epoch 286/300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 907.3022 - val_loss: 896.0404\n",
      "Epoch 287/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 910.3588 - val_loss: 893.3648\n",
      "Epoch 288/300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 904.0081 - val_loss: 897.1325\n",
      "Epoch 289/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 902.7429 - val_loss: 895.3449\n",
      "Epoch 290/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 907.0959 - val_loss: 898.6578\n",
      "Epoch 291/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 901.6502 - val_loss: 893.1552\n",
      "Epoch 292/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 906.7452 - val_loss: 893.3661\n",
      "Epoch 293/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 902.0270 - val_loss: 898.2590\n",
      "Epoch 294/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 900.1171 - val_loss: 893.6967\n",
      "Epoch 295/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 902.7288 - val_loss: 891.7545\n",
      "Epoch 296/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 901.4043 - val_loss: 893.9457\n",
      "Epoch 297/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 899.7972 - val_loss: 892.8425\n",
      "Epoch 298/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 899.6180 - val_loss: 895.8703\n",
      "Epoch 299/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 903.0931 - val_loss: 903.8281\n",
      "Epoch 300/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 904.6613 - val_loss: 893.3024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7b8d0114e8c0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),batch_size=128,epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E_gHNbI-O_Pt",
    "outputId": "d1ac551f-e35f-4f9b-81de-b4cde7c89b9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 19)                323       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 19)                380       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 19)                380       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 19)                380       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 19)                380       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 20        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1863 (7.28 KB)\n",
      "Trainable params: 1863 (7.28 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "LQt0bFIHPxQq"
   },
   "outputs": [],
   "source": [
    "loss_df=pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "ZW7xFUbLPz1S",
    "outputId": "d734fdc3-41df-4bbc-b963-dfd79a83e42b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VIKS-bCfP153",
    "outputId": "598b60b2-7e47-4c98-a714-e4be22103d37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 1s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "tahmin=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "oi6LY9r5P5yC"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ubqc-CXdP8dy",
    "outputId": "c45fda15-606f-4d99-98bb-0dc5cefa1b90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0009760878818559915"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,tahmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bamC1qQRP-iL",
    "outputId": "7387955a-f55b-41fc-d5d9-a90701aaf3c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 904.2383 - val_loss: 912.7271\n",
      "Epoch 2/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 908.8187 - val_loss: 898.1884\n",
      "Epoch 3/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 904.0589 - val_loss: 900.0566\n",
      "Epoch 4/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 904.1374 - val_loss: 893.7112\n",
      "Epoch 5/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 906.2292 - val_loss: 895.0731\n",
      "Epoch 6/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 901.5757 - val_loss: 893.3795\n",
      "Epoch 7/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 903.2769 - val_loss: 897.1829\n",
      "Epoch 8/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 900.5612 - val_loss: 893.9908\n",
      "Epoch 9/1300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 902.5112 - val_loss: 897.4704\n",
      "Epoch 10/1300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 904.7983 - val_loss: 910.4030\n",
      "Epoch 11/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 907.3837 - val_loss: 893.1452\n",
      "Epoch 12/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 901.7932 - val_loss: 891.4741\n",
      "Epoch 13/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 906.0735 - val_loss: 895.0818\n",
      "Epoch 14/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 904.9029 - val_loss: 893.6722\n",
      "Epoch 15/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 901.5239 - val_loss: 893.2830\n",
      "Epoch 16/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 900.9219 - val_loss: 893.4034\n",
      "Epoch 17/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 913.8040 - val_loss: 902.1942\n",
      "Epoch 18/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 903.0697 - val_loss: 892.9072\n",
      "Epoch 19/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 902.2940 - val_loss: 892.4585\n",
      "Epoch 20/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 905.7289 - val_loss: 903.5551\n",
      "Epoch 21/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 907.4171 - val_loss: 896.4379\n",
      "Epoch 22/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 900.4365 - val_loss: 893.4167\n",
      "Epoch 23/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 902.8420 - val_loss: 903.9940\n",
      "Epoch 24/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 902.5518 - val_loss: 893.0975\n",
      "Epoch 25/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 904.4709 - val_loss: 897.2418\n",
      "Epoch 26/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 901.3481 - val_loss: 898.2003\n",
      "Epoch 27/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 902.8959 - val_loss: 894.5587\n",
      "Epoch 28/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 901.6450 - val_loss: 898.3079\n",
      "Epoch 29/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 900.9203 - val_loss: 895.5942\n",
      "Epoch 30/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 904.3853 - val_loss: 900.3216\n",
      "Epoch 31/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 904.3862 - val_loss: 892.9030\n",
      "Epoch 32/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 903.5475 - val_loss: 899.4641\n",
      "Epoch 33/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 904.8582 - val_loss: 895.9094\n",
      "Epoch 34/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 905.0298 - val_loss: 894.3283\n",
      "Epoch 35/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 901.3414 - val_loss: 894.1939\n",
      "Epoch 36/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 903.3054 - val_loss: 895.8165\n",
      "Epoch 37/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 904.0677 - val_loss: 897.2599\n",
      "Epoch 38/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 901.9047 - val_loss: 895.4981\n",
      "Epoch 39/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 900.8671 - val_loss: 925.1599\n",
      "Epoch 40/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 940.4890 - val_loss: 897.4020\n",
      "Epoch 41/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 898.4400 - val_loss: 891.3502\n",
      "Epoch 42/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 898.6642 - val_loss: 893.2332\n",
      "Epoch 43/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 901.3716 - val_loss: 891.0510\n",
      "Epoch 44/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 898.5137 - val_loss: 900.1948\n",
      "Epoch 45/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 902.8405 - val_loss: 893.8221\n",
      "Epoch 46/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 900.1791 - val_loss: 892.0947\n",
      "Epoch 47/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 898.9769 - val_loss: 893.9319\n",
      "Epoch 48/1300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 901.8452 - val_loss: 899.5738\n",
      "Epoch 49/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 907.6759 - val_loss: 895.8851\n",
      "Epoch 50/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 904.1542 - val_loss: 892.8207\n",
      "Epoch 51/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 898.5002 - val_loss: 892.9157\n",
      "Epoch 52/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 898.2775 - val_loss: 892.3834\n",
      "Epoch 53/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 903.9296 - val_loss: 893.5630\n",
      "Epoch 54/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 900.4832 - val_loss: 898.1219\n",
      "Epoch 55/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 898.6639 - val_loss: 907.1214\n",
      "Epoch 56/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 901.1786 - val_loss: 893.5491\n",
      "Epoch 57/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 905.0842 - val_loss: 908.3416\n",
      "Epoch 58/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 924.1810 - val_loss: 894.0918\n",
      "Epoch 59/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 901.9414 - val_loss: 894.5280\n",
      "Epoch 60/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 903.7800 - val_loss: 899.3719\n",
      "Epoch 61/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 909.6652 - val_loss: 896.5403\n",
      "Epoch 62/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 902.3223 - val_loss: 897.1482\n",
      "Epoch 63/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 902.0856 - val_loss: 894.8444\n",
      "Epoch 64/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 899.9321 - val_loss: 892.7283\n",
      "Epoch 65/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 897.6420 - val_loss: 891.6851\n",
      "Epoch 66/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 903.9861 - val_loss: 894.2177\n",
      "Epoch 67/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 900.3049 - val_loss: 895.2811\n",
      "Epoch 68/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 901.5472 - val_loss: 900.0518\n",
      "Epoch 69/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 900.6312 - val_loss: 892.5333\n",
      "Epoch 70/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 898.3918 - val_loss: 891.2920\n",
      "Epoch 71/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 902.7625 - val_loss: 924.7511\n",
      "Epoch 72/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 905.5560 - val_loss: 893.3069\n",
      "Epoch 73/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 899.3497 - val_loss: 892.3531\n",
      "Epoch 74/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 896.1147 - val_loss: 894.5309\n",
      "Epoch 75/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 900.2021 - val_loss: 901.8971\n",
      "Epoch 76/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 901.0997 - val_loss: 890.9094\n",
      "Epoch 77/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 897.9847 - val_loss: 892.5238\n",
      "Epoch 78/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 899.0079 - val_loss: 900.7467\n",
      "Epoch 79/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 894.6609 - val_loss: 892.0800\n",
      "Epoch 80/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 894.3941 - val_loss: 895.8680\n",
      "Epoch 81/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 900.4158 - val_loss: 913.8652\n",
      "Epoch 82/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 901.1791 - val_loss: 893.1606\n",
      "Epoch 83/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 898.3918 - val_loss: 892.3621\n",
      "Epoch 84/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 897.6741 - val_loss: 890.6671\n",
      "Epoch 85/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 894.6556 - val_loss: 891.8016\n",
      "Epoch 86/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 895.1315 - val_loss: 890.0335\n",
      "Epoch 87/1300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 898.5652 - val_loss: 904.0803\n",
      "Epoch 88/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 899.3890 - val_loss: 889.0181\n",
      "Epoch 89/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 892.7755 - val_loss: 901.4896\n",
      "Epoch 90/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 897.9919 - val_loss: 895.5195\n",
      "Epoch 91/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 891.9752 - val_loss: 896.2964\n",
      "Epoch 92/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 904.6006 - val_loss: 891.5981\n",
      "Epoch 93/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 894.0589 - val_loss: 893.2091\n",
      "Epoch 94/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 895.2316 - val_loss: 901.1006\n",
      "Epoch 95/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 897.6490 - val_loss: 899.3168\n",
      "Epoch 96/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 896.3155 - val_loss: 889.0570\n",
      "Epoch 97/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 892.7607 - val_loss: 893.3442\n",
      "Epoch 98/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 894.6736 - val_loss: 905.7098\n",
      "Epoch 99/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 904.0586 - val_loss: 889.3353\n",
      "Epoch 100/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 896.1874 - val_loss: 890.3958\n",
      "Epoch 101/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 893.0377 - val_loss: 892.9025\n",
      "Epoch 102/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 899.0803 - val_loss: 893.5779\n",
      "Epoch 103/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 903.5975 - val_loss: 895.6861\n",
      "Epoch 104/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 905.4107 - val_loss: 922.8546\n",
      "Epoch 105/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 899.4219 - val_loss: 888.4819\n",
      "Epoch 106/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 894.5257 - val_loss: 885.8788\n",
      "Epoch 107/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 899.5784 - val_loss: 922.9302\n",
      "Epoch 108/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 903.0658 - val_loss: 888.3841\n",
      "Epoch 109/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 893.8357 - val_loss: 887.2001\n",
      "Epoch 110/1300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 894.1487 - val_loss: 886.0300\n",
      "Epoch 111/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 903.8977 - val_loss: 890.3828\n",
      "Epoch 112/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 893.9892 - val_loss: 905.0716\n",
      "Epoch 113/1300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 904.4089 - val_loss: 923.8917\n",
      "Epoch 114/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 902.5162 - val_loss: 896.1538\n",
      "Epoch 115/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 892.8032 - val_loss: 893.7380\n",
      "Epoch 116/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 902.6301 - val_loss: 896.1170\n",
      "Epoch 117/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 898.2867 - val_loss: 890.8520\n",
      "Epoch 118/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 901.7092 - val_loss: 922.9996\n",
      "Epoch 119/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 899.4422 - val_loss: 890.6760\n",
      "Epoch 120/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 894.3698 - val_loss: 887.9619\n",
      "Epoch 121/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 895.2340 - val_loss: 889.1743\n",
      "Epoch 122/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 889.0760 - val_loss: 890.5439\n",
      "Epoch 123/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 895.9554 - val_loss: 932.9637\n",
      "Epoch 124/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 900.4969 - val_loss: 888.9365\n",
      "Epoch 125/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 889.6096 - val_loss: 887.3815\n",
      "Epoch 126/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 891.5301 - val_loss: 894.1844\n",
      "Epoch 127/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 896.5717 - val_loss: 896.4439\n",
      "Epoch 128/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 895.6780 - val_loss: 898.0542\n",
      "Epoch 129/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 891.1897 - val_loss: 886.8129\n",
      "Epoch 130/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 889.3655 - val_loss: 887.0818\n",
      "Epoch 131/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 890.8977 - val_loss: 988.2063\n",
      "Epoch 132/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 899.5062 - val_loss: 889.5704\n",
      "Epoch 133/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 895.0558 - val_loss: 892.6914\n",
      "Epoch 134/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 886.7235 - val_loss: 887.1987\n",
      "Epoch 135/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 892.5925 - val_loss: 895.1207\n",
      "Epoch 136/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 896.9507 - val_loss: 893.3303\n",
      "Epoch 137/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 891.5258 - val_loss: 886.1150\n",
      "Epoch 138/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 894.7078 - val_loss: 887.8416\n",
      "Epoch 139/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 886.3948 - val_loss: 896.8788\n",
      "Epoch 140/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 891.8510 - val_loss: 897.5864\n",
      "Epoch 141/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 900.5389 - val_loss: 892.3971\n",
      "Epoch 142/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 888.5186 - val_loss: 885.2246\n",
      "Epoch 143/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 891.0467 - val_loss: 885.9332\n",
      "Epoch 144/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 885.6857 - val_loss: 896.1394\n",
      "Epoch 145/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 897.0211 - val_loss: 897.6923\n",
      "Epoch 146/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 888.5731 - val_loss: 888.1011\n",
      "Epoch 147/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 892.9760 - val_loss: 885.4255\n",
      "Epoch 148/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 888.2935 - val_loss: 884.2938\n",
      "Epoch 149/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 890.4086 - val_loss: 909.6277\n",
      "Epoch 150/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 893.6502 - val_loss: 886.4434\n",
      "Epoch 151/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 889.5532 - val_loss: 883.6134\n",
      "Epoch 152/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 891.1860 - val_loss: 886.1821\n",
      "Epoch 153/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 887.4620 - val_loss: 884.4597\n",
      "Epoch 154/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 885.6461 - val_loss: 885.8580\n",
      "Epoch 155/1300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 889.6147 - val_loss: 886.4432\n",
      "Epoch 156/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 888.3200 - val_loss: 888.6401\n",
      "Epoch 157/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 885.9753 - val_loss: 888.7828\n",
      "Epoch 158/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 887.2563 - val_loss: 892.5810\n",
      "Epoch 159/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 885.2063 - val_loss: 886.9371\n",
      "Epoch 160/1300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 884.4658 - val_loss: 886.5220\n",
      "Epoch 161/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 884.2802 - val_loss: 892.7615\n",
      "Epoch 162/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 887.5413 - val_loss: 897.6426\n",
      "Epoch 163/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 887.9266 - val_loss: 885.7635\n",
      "Epoch 164/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 885.2825 - val_loss: 883.3860\n",
      "Epoch 165/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 885.4497 - val_loss: 884.4166\n",
      "Epoch 166/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 886.4404 - val_loss: 895.1483\n",
      "Epoch 167/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 886.7627 - val_loss: 892.0732\n",
      "Epoch 168/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 889.6327 - val_loss: 881.3334\n",
      "Epoch 169/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 883.8008 - val_loss: 882.6867\n",
      "Epoch 170/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 886.8669 - val_loss: 894.2449\n",
      "Epoch 171/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 889.4585 - val_loss: 895.2189\n",
      "Epoch 172/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 890.5738 - val_loss: 885.0756\n",
      "Epoch 173/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 897.1158 - val_loss: 886.2198\n",
      "Epoch 174/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 887.8924 - val_loss: 899.9686\n",
      "Epoch 175/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 890.2960 - val_loss: 900.7955\n",
      "Epoch 176/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 884.5290 - val_loss: 887.6787\n",
      "Epoch 177/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 882.6572 - val_loss: 890.2858\n",
      "Epoch 178/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 883.8638 - val_loss: 887.1792\n",
      "Epoch 179/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 893.9772 - val_loss: 890.4813\n",
      "Epoch 180/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 887.3036 - val_loss: 904.2410\n",
      "Epoch 181/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 884.3478 - val_loss: 884.7182\n",
      "Epoch 182/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 886.0375 - val_loss: 891.0665\n",
      "Epoch 183/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 886.3304 - val_loss: 898.5125\n",
      "Epoch 184/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 886.2913 - val_loss: 883.6934\n",
      "Epoch 185/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 885.0911 - val_loss: 883.9193\n",
      "Epoch 186/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 889.1478 - val_loss: 976.5308\n",
      "Epoch 187/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 889.1096 - val_loss: 882.5586\n",
      "Epoch 188/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 892.3088 - val_loss: 887.0981\n",
      "Epoch 189/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 884.8329 - val_loss: 881.4861\n",
      "Epoch 190/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 883.0834 - val_loss: 880.8813\n",
      "Epoch 191/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 880.8949 - val_loss: 886.7828\n",
      "Epoch 192/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 882.8524 - val_loss: 881.5441\n",
      "Epoch 193/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 883.1646 - val_loss: 883.8959\n",
      "Epoch 194/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 884.0828 - val_loss: 888.6423\n",
      "Epoch 195/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 886.0143 - val_loss: 893.6616\n",
      "Epoch 196/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 884.0927 - val_loss: 887.9524\n",
      "Epoch 197/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 886.0481 - val_loss: 882.4061\n",
      "Epoch 198/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 885.7686 - val_loss: 900.3900\n",
      "Epoch 199/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 892.3447 - val_loss: 915.0658\n",
      "Epoch 200/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 887.1975 - val_loss: 881.9118\n",
      "Epoch 201/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 887.9106 - val_loss: 883.8262\n",
      "Epoch 202/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 882.3867 - val_loss: 884.3237\n",
      "Epoch 203/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 886.3950 - val_loss: 907.6384\n",
      "Epoch 204/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 891.3383 - val_loss: 879.8029\n",
      "Epoch 205/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 883.6433 - val_loss: 906.4981\n",
      "Epoch 206/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 889.8149 - val_loss: 918.4069\n",
      "Epoch 207/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 888.7334 - val_loss: 885.2516\n",
      "Epoch 208/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 884.7335 - val_loss: 884.0931\n",
      "Epoch 209/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 887.1927 - val_loss: 890.1642\n",
      "Epoch 210/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 882.0435 - val_loss: 882.3747\n",
      "Epoch 211/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 881.8574 - val_loss: 884.1110\n",
      "Epoch 212/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 881.0118 - val_loss: 891.0748\n",
      "Epoch 213/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 880.6055 - val_loss: 889.7043\n",
      "Epoch 214/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 881.1391 - val_loss: 883.4886\n",
      "Epoch 215/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 881.8126 - val_loss: 882.8781\n",
      "Epoch 216/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 883.2199 - val_loss: 880.4908\n",
      "Epoch 217/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 880.4634 - val_loss: 880.9769\n",
      "Epoch 218/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 880.8621 - val_loss: 888.8737\n",
      "Epoch 219/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 885.0411 - val_loss: 884.3730\n",
      "Epoch 220/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 890.0391 - val_loss: 892.4684\n",
      "Epoch 221/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 883.9032 - val_loss: 888.0122\n",
      "Epoch 222/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 886.2778 - val_loss: 883.1537\n",
      "Epoch 223/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 880.1790 - val_loss: 891.3617\n",
      "Epoch 224/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 884.3238 - val_loss: 896.0508\n",
      "Epoch 225/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 881.1577 - val_loss: 908.7214\n",
      "Epoch 226/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 881.7383 - val_loss: 885.3689\n",
      "Epoch 227/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 883.4053 - val_loss: 884.5979\n",
      "Epoch 228/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 886.1943 - val_loss: 906.7578\n",
      "Epoch 229/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 880.3267 - val_loss: 887.9675\n",
      "Epoch 230/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 880.7310 - val_loss: 897.4238\n",
      "Epoch 231/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 888.8120 - val_loss: 882.2305\n",
      "Epoch 232/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 879.1853 - val_loss: 883.9151\n",
      "Epoch 233/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 883.6194 - val_loss: 879.9432\n",
      "Epoch 234/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 886.6269 - val_loss: 916.7713\n",
      "Epoch 235/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 887.4770 - val_loss: 912.8652\n",
      "Epoch 236/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 880.9527 - val_loss: 895.8945\n",
      "Epoch 237/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 880.1628 - val_loss: 881.4323\n",
      "Epoch 238/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 882.0344 - val_loss: 905.2281\n",
      "Epoch 239/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 883.3284 - val_loss: 887.4160\n",
      "Epoch 240/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 883.0994 - val_loss: 881.1022\n",
      "Epoch 241/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 880.7448 - val_loss: 900.2431\n",
      "Epoch 242/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 882.8644 - val_loss: 884.0752\n",
      "Epoch 243/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 889.8947 - val_loss: 884.4162\n",
      "Epoch 244/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 883.2753 - val_loss: 882.2012\n",
      "Epoch 245/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 881.3712 - val_loss: 886.0145\n",
      "Epoch 246/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 886.2311 - val_loss: 893.8140\n",
      "Epoch 247/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 883.5281 - val_loss: 883.9677\n",
      "Epoch 248/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 880.8175 - val_loss: 880.0424\n",
      "Epoch 249/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 879.6957 - val_loss: 882.0852\n",
      "Epoch 250/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 892.0370 - val_loss: 895.1505\n",
      "Epoch 251/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 881.2256 - val_loss: 885.4771\n",
      "Epoch 252/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 880.7938 - val_loss: 880.3628\n",
      "Epoch 253/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 881.9034 - val_loss: 897.9958\n",
      "Epoch 254/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 879.9158 - val_loss: 883.3701\n",
      "Epoch 255/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 889.1707 - val_loss: 882.1681\n",
      "Epoch 256/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 881.3292 - val_loss: 898.1647\n",
      "Epoch 257/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 882.6224 - val_loss: 889.2047\n",
      "Epoch 258/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 880.7803 - val_loss: 880.5799\n",
      "Epoch 259/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 883.3883 - val_loss: 892.9164\n",
      "Epoch 260/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 884.2200 - val_loss: 883.1776\n",
      "Epoch 261/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 879.0721 - val_loss: 890.5810\n",
      "Epoch 262/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 880.7380 - val_loss: 896.6996\n",
      "Epoch 263/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 881.3215 - val_loss: 883.6932\n",
      "Epoch 264/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 885.2220 - val_loss: 878.8913\n",
      "Epoch 265/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 878.5731 - val_loss: 881.5114\n",
      "Epoch 266/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 883.2959 - val_loss: 882.5720\n",
      "Epoch 267/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 878.9702 - val_loss: 885.5304\n",
      "Epoch 268/1300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 878.2735 - val_loss: 893.7325\n",
      "Epoch 269/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 891.1183 - val_loss: 889.0692\n",
      "Epoch 270/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 881.6994 - val_loss: 884.1642\n",
      "Epoch 271/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 882.0272 - val_loss: 887.9709\n",
      "Epoch 272/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 878.6800 - val_loss: 880.5541\n",
      "Epoch 273/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 880.7504 - val_loss: 885.6510\n",
      "Epoch 274/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 879.6212 - val_loss: 879.0306\n",
      "Epoch 275/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 881.1962 - val_loss: 968.6125\n",
      "Epoch 276/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 883.6189 - val_loss: 882.5615\n",
      "Epoch 277/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 885.1867 - val_loss: 890.8336\n",
      "Epoch 278/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 881.2726 - val_loss: 881.2505\n",
      "Epoch 279/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 882.3182 - val_loss: 888.3445\n",
      "Epoch 280/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 882.2468 - val_loss: 887.4793\n",
      "Epoch 281/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 879.2568 - val_loss: 896.5276\n",
      "Epoch 282/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 883.2627 - val_loss: 894.5877\n",
      "Epoch 283/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 883.9865 - val_loss: 879.5836\n",
      "Epoch 284/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 883.3654 - val_loss: 883.2086\n",
      "Epoch 285/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 881.8609 - val_loss: 894.1699\n",
      "Epoch 286/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 881.9445 - val_loss: 880.3137\n",
      "Epoch 287/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 879.0247 - val_loss: 888.9179\n",
      "Epoch 288/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 879.0726 - val_loss: 887.1113\n",
      "Epoch 289/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 880.8065 - val_loss: 889.0396\n",
      "Epoch 290/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 880.5505 - val_loss: 903.6863\n",
      "Epoch 291/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 883.9384 - val_loss: 879.5381\n",
      "Epoch 292/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 876.9426 - val_loss: 883.0452\n",
      "Epoch 293/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 877.8391 - val_loss: 880.1501\n",
      "Epoch 294/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 881.9252 - val_loss: 894.5760\n",
      "Epoch 295/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 884.2629 - val_loss: 904.7662\n",
      "Epoch 296/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 882.1536 - val_loss: 882.8467\n",
      "Epoch 297/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 890.0827 - val_loss: 879.6375\n",
      "Epoch 298/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 876.9000 - val_loss: 897.2273\n",
      "Epoch 299/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 880.7068 - val_loss: 879.9513\n",
      "Epoch 300/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 878.3999 - val_loss: 882.8127\n",
      "Epoch 301/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 883.4594 - val_loss: 881.4832\n",
      "Epoch 302/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 883.4442 - val_loss: 883.2446\n",
      "Epoch 303/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 877.6159 - val_loss: 881.6901\n",
      "Epoch 304/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 882.0430 - val_loss: 882.0428\n",
      "Epoch 305/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 882.8926 - val_loss: 879.2996\n",
      "Epoch 306/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 879.3209 - val_loss: 881.1672\n",
      "Epoch 307/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 878.2989 - val_loss: 892.9941\n",
      "Epoch 308/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 885.9452 - val_loss: 885.1221\n",
      "Epoch 309/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 886.0252 - val_loss: 902.5632\n",
      "Epoch 310/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 880.5475 - val_loss: 879.1492\n",
      "Epoch 311/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 878.3109 - val_loss: 884.3160\n",
      "Epoch 312/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 879.5778 - val_loss: 883.7480\n",
      "Epoch 313/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 881.9272 - val_loss: 886.1136\n",
      "Epoch 314/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 879.4364 - val_loss: 886.8427\n",
      "Epoch 315/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 880.1012 - val_loss: 890.9231\n",
      "Epoch 316/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 877.0909 - val_loss: 892.7711\n",
      "Epoch 317/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 883.2365 - val_loss: 888.3608\n",
      "Epoch 318/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 879.4856 - val_loss: 881.2319\n",
      "Epoch 319/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 880.8926 - val_loss: 902.0997\n",
      "Epoch 320/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 879.5854 - val_loss: 883.1560\n",
      "Epoch 321/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 878.4597 - val_loss: 887.2623\n",
      "Epoch 322/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 878.4131 - val_loss: 882.5629\n",
      "Epoch 323/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 879.7554 - val_loss: 885.0206\n",
      "Epoch 324/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 879.6624 - val_loss: 890.5953\n",
      "Epoch 325/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 879.4310 - val_loss: 885.6162\n",
      "Epoch 326/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 878.9559 - val_loss: 892.6483\n",
      "Epoch 327/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 882.7022 - val_loss: 909.2126\n",
      "Epoch 328/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 882.7308 - val_loss: 896.3603\n",
      "Epoch 329/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 880.3871 - val_loss: 881.9453\n",
      "Epoch 330/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 879.3264 - val_loss: 887.3920\n",
      "Epoch 331/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 881.1363 - val_loss: 882.5424\n",
      "Epoch 332/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 879.0283 - val_loss: 902.2042\n",
      "Epoch 333/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 882.1982 - val_loss: 881.8710\n",
      "Epoch 334/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 881.5174 - val_loss: 900.8412\n",
      "Epoch 335/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 878.9896 - val_loss: 896.9622\n",
      "Epoch 336/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 879.0165 - val_loss: 881.0074\n",
      "Epoch 337/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 886.0374 - val_loss: 883.4287\n",
      "Epoch 338/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 878.1961 - val_loss: 881.8765\n",
      "Epoch 339/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 877.7990 - val_loss: 881.0504\n",
      "Epoch 340/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 888.7371 - val_loss: 879.3995\n",
      "Epoch 341/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 878.9312 - val_loss: 913.9386\n",
      "Epoch 342/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 884.8676 - val_loss: 884.3034\n",
      "Epoch 343/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 879.0084 - val_loss: 892.0625\n",
      "Epoch 344/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 879.9946 - val_loss: 889.3893\n",
      "Epoch 345/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 885.5071 - val_loss: 879.7862\n",
      "Epoch 346/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 881.1598 - val_loss: 906.4317\n",
      "Epoch 347/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 882.5872 - val_loss: 879.8214\n",
      "Epoch 348/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 880.7524 - val_loss: 882.9718\n",
      "Epoch 349/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 879.8122 - val_loss: 882.6445\n",
      "Epoch 350/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 880.1317 - val_loss: 891.5939\n",
      "Epoch 351/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 880.7306 - val_loss: 888.3254\n",
      "Epoch 352/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 878.4560 - val_loss: 888.8727\n",
      "Epoch 353/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 880.1333 - val_loss: 891.7713\n",
      "Epoch 354/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 877.5713 - val_loss: 884.9540\n",
      "Epoch 355/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 880.7100 - val_loss: 890.3381\n",
      "Epoch 356/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 878.1301 - val_loss: 886.4839\n",
      "Epoch 357/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 882.5367 - val_loss: 903.0792\n",
      "Epoch 358/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 876.2797 - val_loss: 881.6893\n",
      "Epoch 359/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 878.5177 - val_loss: 891.6169\n",
      "Epoch 360/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 877.5474 - val_loss: 890.8735\n",
      "Epoch 361/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 885.5804 - val_loss: 880.8655\n",
      "Epoch 362/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 879.3855 - val_loss: 886.0356\n",
      "Epoch 363/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 878.3703 - val_loss: 883.6362\n",
      "Epoch 364/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 880.8842 - val_loss: 900.4694\n",
      "Epoch 365/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 882.0317 - val_loss: 879.8640\n",
      "Epoch 366/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 878.8837 - val_loss: 888.5571\n",
      "Epoch 367/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 875.3558 - val_loss: 883.5177\n",
      "Epoch 368/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 878.9438 - val_loss: 884.5281\n",
      "Epoch 369/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 879.3910 - val_loss: 879.6400\n",
      "Epoch 370/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 876.3551 - val_loss: 884.3036\n",
      "Epoch 371/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 880.2537 - val_loss: 904.6528\n",
      "Epoch 372/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 889.1331 - val_loss: 884.4127\n",
      "Epoch 373/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 882.3869 - val_loss: 887.6853\n",
      "Epoch 374/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 879.7143 - val_loss: 883.4146\n",
      "Epoch 375/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 879.4637 - val_loss: 897.9501\n",
      "Epoch 376/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 877.6649 - val_loss: 889.4268\n",
      "Epoch 377/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 875.1927 - val_loss: 881.9266\n",
      "Epoch 378/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 879.0723 - val_loss: 881.0810\n",
      "Epoch 379/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 881.1578 - val_loss: 883.8880\n",
      "Epoch 380/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 878.8337 - val_loss: 881.5251\n",
      "Epoch 381/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 878.6793 - val_loss: 881.1741\n",
      "Epoch 382/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 876.0741 - val_loss: 880.5534\n",
      "Epoch 383/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 879.3192 - val_loss: 882.3264\n",
      "Epoch 384/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 876.9498 - val_loss: 883.7250\n",
      "Epoch 385/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 882.1550 - val_loss: 886.5170\n",
      "Epoch 386/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 879.1400 - val_loss: 914.3555\n",
      "Epoch 387/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 880.0346 - val_loss: 885.4314\n",
      "Epoch 388/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 876.9496 - val_loss: 882.9355\n",
      "Epoch 389/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 876.5373 - val_loss: 883.0182\n",
      "Epoch 390/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 881.0245 - val_loss: 884.3170\n",
      "Epoch 391/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 878.2072 - val_loss: 881.6768\n",
      "Epoch 392/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 875.2433 - val_loss: 897.7699\n",
      "Epoch 393/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 882.4235 - val_loss: 885.0738\n",
      "Epoch 394/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 884.1871 - val_loss: 890.2186\n",
      "Epoch 395/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 878.8081 - val_loss: 879.3613\n",
      "Epoch 396/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 875.3019 - val_loss: 889.0809\n",
      "Epoch 397/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 876.3878 - val_loss: 891.4374\n",
      "Epoch 398/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 877.2007 - val_loss: 882.0909\n",
      "Epoch 399/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 874.4507 - val_loss: 886.7006\n",
      "Epoch 400/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 875.9310 - val_loss: 883.3167\n",
      "Epoch 401/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 878.8188 - val_loss: 880.5194\n",
      "Epoch 402/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 876.5654 - val_loss: 884.4414\n",
      "Epoch 403/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 875.6623 - val_loss: 883.0981\n",
      "Epoch 404/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 877.1411 - val_loss: 889.4578\n",
      "Epoch 405/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 878.5879 - val_loss: 880.4499\n",
      "Epoch 406/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 879.4872 - val_loss: 884.1210\n",
      "Epoch 407/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 876.8207 - val_loss: 882.3493\n",
      "Epoch 408/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 878.0649 - val_loss: 879.5845\n",
      "Epoch 409/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 875.6126 - val_loss: 885.0824\n",
      "Epoch 410/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 881.7736 - val_loss: 891.5690\n",
      "Epoch 411/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 877.0358 - val_loss: 888.7557\n",
      "Epoch 412/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 878.1359 - val_loss: 883.2214\n",
      "Epoch 413/1300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 876.6860 - val_loss: 881.8790\n",
      "Epoch 414/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 880.8906 - val_loss: 898.6718\n",
      "Epoch 415/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 881.2992 - val_loss: 880.3935\n",
      "Epoch 416/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 876.0687 - val_loss: 880.8593\n",
      "Epoch 417/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 875.8704 - val_loss: 885.0067\n",
      "Epoch 418/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 879.2112 - val_loss: 883.6189\n",
      "Epoch 419/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 878.1669 - val_loss: 884.5704\n",
      "Epoch 420/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 881.3058 - val_loss: 887.0647\n",
      "Epoch 421/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 878.9666 - val_loss: 885.3046\n",
      "Epoch 422/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 880.0403 - val_loss: 881.4911\n",
      "Epoch 423/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 880.2538 - val_loss: 886.1307\n",
      "Epoch 424/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 876.7546 - val_loss: 880.3341\n",
      "Epoch 425/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 878.5922 - val_loss: 879.7004\n",
      "Epoch 426/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 878.1603 - val_loss: 882.7109\n",
      "Epoch 427/1300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 877.0530 - val_loss: 889.5524\n",
      "Epoch 428/1300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 875.5635 - val_loss: 881.2520\n",
      "Epoch 429/1300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 876.0342 - val_loss: 880.3222\n",
      "Epoch 430/1300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 878.6087 - val_loss: 894.9236\n",
      "Epoch 431/1300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 876.3040 - val_loss: 883.6937\n",
      "Epoch 432/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 878.5289 - val_loss: 880.4839\n",
      "Epoch 433/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 874.6967 - val_loss: 882.7188\n",
      "Epoch 434/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 875.2589 - val_loss: 884.3699\n",
      "Epoch 435/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 878.3774 - val_loss: 880.5952\n",
      "Epoch 436/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 877.3615 - val_loss: 882.8052\n",
      "Epoch 437/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 877.5904 - val_loss: 885.9995\n",
      "Epoch 438/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 876.1581 - val_loss: 883.3763\n",
      "Epoch 439/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 876.4345 - val_loss: 881.9886\n",
      "Epoch 440/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 876.9879 - val_loss: 890.2489\n",
      "Epoch 441/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 876.4719 - val_loss: 880.8507\n",
      "Epoch 442/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 880.0279 - val_loss: 880.4766\n",
      "Epoch 443/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 874.8707 - val_loss: 890.0369\n",
      "Epoch 444/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 876.8537 - val_loss: 883.8121\n",
      "Epoch 445/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 876.1804 - val_loss: 882.2104\n",
      "Epoch 446/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 876.4862 - val_loss: 881.7772\n",
      "Epoch 447/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 875.7579 - val_loss: 879.7704\n",
      "Epoch 448/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 876.8289 - val_loss: 884.5438\n",
      "Epoch 449/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 875.9368 - val_loss: 892.4942\n",
      "Epoch 450/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 883.2964 - val_loss: 897.6983\n",
      "Epoch 451/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 884.8198 - val_loss: 883.9368\n",
      "Epoch 452/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 881.7965 - val_loss: 884.6569\n",
      "Epoch 453/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 879.7136 - val_loss: 890.9030\n",
      "Epoch 454/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 879.5564 - val_loss: 882.2413\n",
      "Epoch 455/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 884.2010 - val_loss: 898.9192\n",
      "Epoch 456/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 884.8646 - val_loss: 889.5568\n",
      "Epoch 457/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 880.3568 - val_loss: 898.1443\n",
      "Epoch 458/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 879.8740 - val_loss: 884.3242\n",
      "Epoch 459/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 881.8989 - val_loss: 883.6340\n",
      "Epoch 460/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 877.0630 - val_loss: 887.2222\n",
      "Epoch 461/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 878.9487 - val_loss: 892.3790\n",
      "Epoch 462/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 877.9783 - val_loss: 890.1448\n",
      "Epoch 463/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 882.4168 - val_loss: 881.5334\n",
      "Epoch 464/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 878.4377 - val_loss: 887.3480\n",
      "Epoch 465/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 887.0513 - val_loss: 882.5851\n",
      "Epoch 466/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 877.2522 - val_loss: 883.2343\n",
      "Epoch 467/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 876.8575 - val_loss: 881.2932\n",
      "Epoch 468/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 881.5632 - val_loss: 883.0140\n",
      "Epoch 469/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 877.3488 - val_loss: 889.3069\n",
      "Epoch 470/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 878.8492 - val_loss: 886.0670\n",
      "Epoch 471/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 876.1310 - val_loss: 885.7165\n",
      "Epoch 472/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 879.4850 - val_loss: 886.7549\n",
      "Epoch 473/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 876.1013 - val_loss: 881.2655\n",
      "Epoch 474/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 880.5021 - val_loss: 889.8334\n",
      "Epoch 475/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 876.0258 - val_loss: 881.1637\n",
      "Epoch 476/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 878.6019 - val_loss: 881.0575\n",
      "Epoch 477/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 877.1913 - val_loss: 879.7886\n",
      "Epoch 478/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 880.6312 - val_loss: 881.3593\n",
      "Epoch 479/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 876.8894 - val_loss: 885.3246\n",
      "Epoch 480/1300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 876.3670 - val_loss: 889.2024\n",
      "Epoch 481/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 879.9013 - val_loss: 884.4059\n",
      "Epoch 482/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 876.5571 - val_loss: 894.9722\n",
      "Epoch 483/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 879.5139 - val_loss: 886.8721\n",
      "Epoch 484/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 878.1201 - val_loss: 880.0401\n",
      "Epoch 485/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 878.3876 - val_loss: 880.4977\n",
      "Epoch 486/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 879.6144 - val_loss: 882.0125\n",
      "Epoch 487/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 881.8459 - val_loss: 883.1708\n",
      "Epoch 488/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 876.3260 - val_loss: 880.2837\n",
      "Epoch 489/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 881.6224 - val_loss: 894.0445\n",
      "Epoch 490/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 878.3698 - val_loss: 885.5117\n",
      "Epoch 491/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 879.5246 - val_loss: 885.1496\n",
      "Epoch 492/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 874.7853 - val_loss: 882.3465\n",
      "Epoch 493/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 879.2217 - val_loss: 888.1760\n",
      "Epoch 494/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 876.6379 - val_loss: 881.2202\n",
      "Epoch 495/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 880.7943 - val_loss: 882.4269\n",
      "Epoch 496/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 876.7907 - val_loss: 885.7867\n",
      "Epoch 497/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 878.5703 - val_loss: 879.8013\n",
      "Epoch 498/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 877.0245 - val_loss: 882.4757\n",
      "Epoch 499/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 876.4106 - val_loss: 894.5330\n",
      "Epoch 500/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 881.2618 - val_loss: 885.0005\n",
      "Epoch 501/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 877.1374 - val_loss: 884.1034\n",
      "Epoch 502/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 876.2197 - val_loss: 886.3826\n",
      "Epoch 503/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 875.7052 - val_loss: 880.4935\n",
      "Epoch 504/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 877.2636 - val_loss: 881.6925\n",
      "Epoch 505/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 876.5150 - val_loss: 879.7112\n",
      "Epoch 506/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 877.9780 - val_loss: 885.9997\n",
      "Epoch 507/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 880.0662 - val_loss: 880.4005\n",
      "Epoch 508/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 874.3649 - val_loss: 895.2233\n",
      "Epoch 509/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 877.2468 - val_loss: 881.8566\n",
      "Epoch 510/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 879.1080 - val_loss: 888.0502\n",
      "Epoch 511/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 876.2729 - val_loss: 888.5191\n",
      "Epoch 512/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 879.5706 - val_loss: 879.6573\n",
      "Epoch 513/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 877.0614 - val_loss: 883.8381\n",
      "Epoch 514/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 877.5301 - val_loss: 879.1964\n",
      "Epoch 515/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 878.4920 - val_loss: 885.4229\n",
      "Epoch 516/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 876.0157 - val_loss: 881.6891\n",
      "Epoch 517/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 874.4388 - val_loss: 888.2364\n",
      "Epoch 518/1300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 876.7498 - val_loss: 881.2188\n",
      "Epoch 519/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 876.0852 - val_loss: 882.2454\n",
      "Epoch 520/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 883.4309 - val_loss: 880.2735\n",
      "Epoch 521/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 877.7748 - val_loss: 881.1702\n",
      "Epoch 522/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 875.6036 - val_loss: 882.1570\n",
      "Epoch 523/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 878.0358 - val_loss: 880.2850\n",
      "Epoch 524/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 876.3094 - val_loss: 882.8421\n",
      "Epoch 525/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 876.2344 - val_loss: 897.1169\n",
      "Epoch 526/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 877.4784 - val_loss: 882.7004\n",
      "Epoch 527/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 876.2938 - val_loss: 880.3525\n",
      "Epoch 528/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 878.9658 - val_loss: 881.4587\n",
      "Epoch 529/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 873.9493 - val_loss: 884.8024\n",
      "Epoch 530/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 880.1510 - val_loss: 881.8533\n",
      "Epoch 531/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 882.3535 - val_loss: 887.2309\n",
      "Epoch 532/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 879.0452 - val_loss: 879.2507\n",
      "Epoch 533/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 875.6181 - val_loss: 880.6582\n",
      "Epoch 534/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 876.2109 - val_loss: 880.3962\n",
      "Epoch 535/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 877.4368 - val_loss: 888.8683\n",
      "Epoch 536/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 875.2601 - val_loss: 879.8904\n",
      "Epoch 537/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 875.7701 - val_loss: 882.0370\n",
      "Epoch 538/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 876.4485 - val_loss: 887.3772\n",
      "Epoch 539/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 876.3094 - val_loss: 882.5598\n",
      "Epoch 540/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 873.9343 - val_loss: 895.9684\n",
      "Epoch 541/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 881.7050 - val_loss: 889.8898\n",
      "Epoch 542/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 875.4543 - val_loss: 879.2673\n",
      "Epoch 543/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 874.1216 - val_loss: 887.2821\n",
      "Epoch 544/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 875.3596 - val_loss: 882.3964\n",
      "Epoch 545/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 876.6342 - val_loss: 886.6729\n",
      "Epoch 546/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 875.6013 - val_loss: 888.3866\n",
      "Epoch 547/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 874.0657 - val_loss: 886.8089\n",
      "Epoch 548/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 881.3334 - val_loss: 905.2792\n",
      "Epoch 549/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 879.2825 - val_loss: 880.1373\n",
      "Epoch 550/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 875.8481 - val_loss: 886.8585\n",
      "Epoch 551/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 875.2472 - val_loss: 879.6374\n",
      "Epoch 552/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 875.5449 - val_loss: 879.9234\n",
      "Epoch 553/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 876.6700 - val_loss: 887.8759\n",
      "Epoch 554/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 876.6195 - val_loss: 884.4955\n",
      "Epoch 555/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 879.6539 - val_loss: 879.4668\n",
      "Epoch 556/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 876.7445 - val_loss: 879.4921\n",
      "Epoch 557/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 876.4501 - val_loss: 881.1411\n",
      "Epoch 558/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 877.7831 - val_loss: 881.5690\n",
      "Epoch 559/1300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 874.3893 - val_loss: 883.3446\n",
      "Epoch 560/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 875.9173 - val_loss: 881.7841\n",
      "Epoch 561/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 876.3000 - val_loss: 885.5958\n",
      "Epoch 562/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 875.0590 - val_loss: 883.8206\n",
      "Epoch 563/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 877.0529 - val_loss: 887.0976\n",
      "Epoch 564/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 875.9765 - val_loss: 880.8151\n",
      "Epoch 565/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 875.7665 - val_loss: 890.5862\n",
      "Epoch 566/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 876.1121 - val_loss: 883.8987\n",
      "Epoch 567/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 876.6810 - val_loss: 883.0831\n",
      "Epoch 568/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 874.0735 - val_loss: 893.1996\n",
      "Epoch 569/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 877.4313 - val_loss: 882.5594\n",
      "Epoch 570/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 877.4066 - val_loss: 879.0776\n",
      "Epoch 571/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 875.4534 - val_loss: 889.4266\n",
      "Epoch 572/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 873.9409 - val_loss: 880.2015\n",
      "Epoch 573/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 872.4404 - val_loss: 893.6927\n",
      "Epoch 574/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 881.4238 - val_loss: 887.4485\n",
      "Epoch 575/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 875.1636 - val_loss: 881.2372\n",
      "Epoch 576/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 875.8932 - val_loss: 879.7876\n",
      "Epoch 577/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 881.0717 - val_loss: 880.2244\n",
      "Epoch 578/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 877.6240 - val_loss: 880.3915\n",
      "Epoch 579/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 877.0660 - val_loss: 881.7031\n",
      "Epoch 580/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 874.6428 - val_loss: 881.3010\n",
      "Epoch 581/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 877.1877 - val_loss: 887.2404\n",
      "Epoch 582/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 875.6967 - val_loss: 880.7043\n",
      "Epoch 583/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 877.5581 - val_loss: 883.6065\n",
      "Epoch 584/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 876.0444 - val_loss: 891.4815\n",
      "Epoch 585/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 878.9741 - val_loss: 880.2341\n",
      "Epoch 586/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 875.6765 - val_loss: 881.4929\n",
      "Epoch 587/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 876.6752 - val_loss: 884.3114\n",
      "Epoch 588/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 874.5398 - val_loss: 880.5233\n",
      "Epoch 589/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 875.6379 - val_loss: 893.3281\n",
      "Epoch 590/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 876.2888 - val_loss: 879.5963\n",
      "Epoch 591/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 875.8484 - val_loss: 884.7588\n",
      "Epoch 592/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 876.3842 - val_loss: 880.5703\n",
      "Epoch 593/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 875.5635 - val_loss: 883.2405\n",
      "Epoch 594/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 879.7505 - val_loss: 883.3271\n",
      "Epoch 595/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 874.5432 - val_loss: 880.4785\n",
      "Epoch 596/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 879.4084 - val_loss: 880.3884\n",
      "Epoch 597/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 875.1167 - val_loss: 879.3338\n",
      "Epoch 598/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 875.5186 - val_loss: 879.7867\n",
      "Epoch 599/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 878.3452 - val_loss: 885.3588\n",
      "Epoch 600/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 874.3546 - val_loss: 879.9912\n",
      "Epoch 601/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 874.2719 - val_loss: 881.0037\n",
      "Epoch 602/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 874.5569 - val_loss: 880.9913\n",
      "Epoch 603/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 872.9394 - val_loss: 879.8829\n",
      "Epoch 604/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 876.4824 - val_loss: 890.7440\n",
      "Epoch 605/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 877.8400 - val_loss: 882.4736\n",
      "Epoch 606/1300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 875.6871 - val_loss: 888.1494\n",
      "Epoch 607/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 876.7634 - val_loss: 880.7551\n",
      "Epoch 608/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 875.5306 - val_loss: 881.8739\n",
      "Epoch 609/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 877.3881 - val_loss: 879.7539\n",
      "Epoch 610/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 875.2115 - val_loss: 885.9719\n",
      "Epoch 611/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 877.1217 - val_loss: 879.2230\n",
      "Epoch 612/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 873.8868 - val_loss: 883.5072\n",
      "Epoch 613/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 874.9926 - val_loss: 883.1295\n",
      "Epoch 614/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 874.6096 - val_loss: 886.0326\n",
      "Epoch 615/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 874.5442 - val_loss: 883.1406\n",
      "Epoch 616/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 874.3947 - val_loss: 881.8873\n",
      "Epoch 617/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 874.9304 - val_loss: 885.6938\n",
      "Epoch 618/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 878.7697 - val_loss: 880.1479\n",
      "Epoch 619/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 873.8777 - val_loss: 880.5706\n",
      "Epoch 620/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 872.8679 - val_loss: 887.1574\n",
      "Epoch 621/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 874.1682 - val_loss: 896.7569\n",
      "Epoch 622/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 878.5947 - val_loss: 881.0017\n",
      "Epoch 623/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 876.6741 - val_loss: 879.8804\n",
      "Epoch 624/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 874.5380 - val_loss: 882.5458\n",
      "Epoch 625/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 875.0955 - val_loss: 879.5362\n",
      "Epoch 626/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 875.6695 - val_loss: 880.0800\n",
      "Epoch 627/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 874.1371 - val_loss: 882.6304\n",
      "Epoch 628/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 874.1206 - val_loss: 884.2015\n",
      "Epoch 629/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 879.8551 - val_loss: 896.5444\n",
      "Epoch 630/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 878.6420 - val_loss: 910.3489\n",
      "Epoch 631/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 876.6174 - val_loss: 881.5436\n",
      "Epoch 632/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 873.3996 - val_loss: 884.3668\n",
      "Epoch 633/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 875.4711 - val_loss: 880.3215\n",
      "Epoch 634/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 875.8817 - val_loss: 879.8917\n",
      "Epoch 635/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 877.1035 - val_loss: 881.9275\n",
      "Epoch 636/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 874.8277 - val_loss: 882.2934\n",
      "Epoch 637/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 873.7900 - val_loss: 880.4008\n",
      "Epoch 638/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 875.6379 - val_loss: 879.9127\n",
      "Epoch 639/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 873.3840 - val_loss: 882.3351\n",
      "Epoch 640/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 873.3237 - val_loss: 880.1717\n",
      "Epoch 641/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 873.8624 - val_loss: 881.3781\n",
      "Epoch 642/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 877.1425 - val_loss: 881.4434\n",
      "Epoch 643/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 875.4350 - val_loss: 878.9506\n",
      "Epoch 644/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 877.9402 - val_loss: 882.4196\n",
      "Epoch 645/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 878.4188 - val_loss: 884.2804\n",
      "Epoch 646/1300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 875.1602 - val_loss: 881.1660\n",
      "Epoch 647/1300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 875.7969 - val_loss: 881.0773\n",
      "Epoch 648/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 876.5054 - val_loss: 880.9586\n",
      "Epoch 649/1300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 874.8729 - val_loss: 884.8848\n",
      "Epoch 650/1300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 878.3618 - val_loss: 895.5422\n",
      "Epoch 651/1300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 882.2850 - val_loss: 881.2120\n",
      "Epoch 652/1300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 872.8136 - val_loss: 896.3068\n",
      "Epoch 653/1300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 876.8762 - val_loss: 883.0514\n",
      "Epoch 654/1300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 878.0773 - val_loss: 879.1370\n",
      "Epoch 655/1300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 873.9906 - val_loss: 878.2775\n",
      "Epoch 656/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 873.3603 - val_loss: 887.4044\n",
      "Epoch 657/1300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 875.8432 - val_loss: 889.1638\n",
      "Epoch 658/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 873.7797 - val_loss: 885.9363\n",
      "Epoch 659/1300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 873.4498 - val_loss: 880.1564\n",
      "Epoch 660/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 871.1118 - val_loss: 887.4121\n",
      "Epoch 661/1300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 874.1528 - val_loss: 879.5554\n",
      "Epoch 662/1300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 874.5679 - val_loss: 895.7587\n",
      "Epoch 663/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 873.5308 - val_loss: 880.1470\n",
      "Epoch 664/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 872.8240 - val_loss: 883.3345\n",
      "Epoch 665/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 873.3864 - val_loss: 880.0393\n",
      "Epoch 666/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 873.7750 - val_loss: 884.3796\n",
      "Epoch 667/1300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 873.0765 - val_loss: 881.3123\n",
      "Epoch 668/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 873.4049 - val_loss: 878.1796\n",
      "Epoch 669/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 874.7387 - val_loss: 889.5841\n",
      "Epoch 670/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 874.2527 - val_loss: 878.0738\n",
      "Epoch 671/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 872.9393 - val_loss: 880.7221\n",
      "Epoch 672/1300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 871.2557 - val_loss: 882.0801\n",
      "Epoch 673/1300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 875.6311 - val_loss: 878.1433\n",
      "Epoch 674/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 872.4479 - val_loss: 886.1214\n",
      "Epoch 675/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 875.3572 - val_loss: 879.3807\n",
      "Epoch 676/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 872.9049 - val_loss: 879.9183\n",
      "Epoch 677/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 875.4370 - val_loss: 886.8474\n",
      "Epoch 678/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 879.4336 - val_loss: 880.4963\n",
      "Epoch 679/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 874.3093 - val_loss: 878.8990\n",
      "Epoch 680/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 871.1249 - val_loss: 881.9534\n",
      "Epoch 681/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 874.3870 - val_loss: 879.3082\n",
      "Epoch 682/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 871.4618 - val_loss: 891.3580\n",
      "Epoch 683/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 874.7678 - val_loss: 884.8245\n",
      "Epoch 684/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 873.2735 - val_loss: 882.5750\n",
      "Epoch 685/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 873.1693 - val_loss: 879.6517\n",
      "Epoch 686/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 872.2200 - val_loss: 880.3610\n",
      "Epoch 687/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 873.3751 - val_loss: 878.9819\n",
      "Epoch 688/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 873.2530 - val_loss: 880.5743\n",
      "Epoch 689/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 873.1152 - val_loss: 879.6721\n",
      "Epoch 690/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 875.3193 - val_loss: 892.7846\n",
      "Epoch 691/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 873.3868 - val_loss: 877.8441\n",
      "Epoch 692/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 874.2910 - val_loss: 887.0317\n",
      "Epoch 693/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 872.6394 - val_loss: 877.4807\n",
      "Epoch 694/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 879.1750 - val_loss: 876.8640\n",
      "Epoch 695/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 870.5919 - val_loss: 881.4545\n",
      "Epoch 696/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 871.5887 - val_loss: 878.5466\n",
      "Epoch 697/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 871.1898 - val_loss: 878.9794\n",
      "Epoch 698/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 871.5687 - val_loss: 886.3903\n",
      "Epoch 699/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 874.8115 - val_loss: 878.1535\n",
      "Epoch 700/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 873.9366 - val_loss: 880.2819\n",
      "Epoch 701/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 871.4082 - val_loss: 879.9688\n",
      "Epoch 702/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 871.7845 - val_loss: 879.7576\n",
      "Epoch 703/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 871.8915 - val_loss: 881.3748\n",
      "Epoch 704/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 872.7778 - val_loss: 881.7708\n",
      "Epoch 705/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 871.6764 - val_loss: 880.3529\n",
      "Epoch 706/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 872.1702 - val_loss: 880.4852\n",
      "Epoch 707/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 875.4842 - val_loss: 882.9405\n",
      "Epoch 708/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 871.4827 - val_loss: 879.4454\n",
      "Epoch 709/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 872.7976 - val_loss: 884.2299\n",
      "Epoch 710/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 872.8303 - val_loss: 889.1678\n",
      "Epoch 711/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 874.8060 - val_loss: 880.2909\n",
      "Epoch 712/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 871.2856 - val_loss: 886.8543\n",
      "Epoch 713/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 872.5770 - val_loss: 878.0898\n",
      "Epoch 714/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 872.8854 - val_loss: 880.7333\n",
      "Epoch 715/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 875.1635 - val_loss: 878.4713\n",
      "Epoch 716/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 873.7328 - val_loss: 880.7138\n",
      "Epoch 717/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 875.0724 - val_loss: 881.6046\n",
      "Epoch 718/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 877.3824 - val_loss: 878.5898\n",
      "Epoch 719/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 877.0222 - val_loss: 884.9335\n",
      "Epoch 720/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 872.1097 - val_loss: 877.5873\n",
      "Epoch 721/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 871.7385 - val_loss: 888.3155\n",
      "Epoch 722/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 874.4941 - val_loss: 877.6990\n",
      "Epoch 723/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 874.1672 - val_loss: 886.0920\n",
      "Epoch 724/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 875.5905 - val_loss: 878.2830\n",
      "Epoch 725/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 870.1877 - val_loss: 879.7253\n",
      "Epoch 726/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 870.2088 - val_loss: 881.1584\n",
      "Epoch 727/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 871.7099 - val_loss: 881.7613\n",
      "Epoch 728/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 872.0759 - val_loss: 878.1948\n",
      "Epoch 729/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 872.6313 - val_loss: 883.9345\n",
      "Epoch 730/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 871.6876 - val_loss: 878.9148\n",
      "Epoch 731/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 873.5191 - val_loss: 879.3959\n",
      "Epoch 732/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 872.8315 - val_loss: 879.2968\n",
      "Epoch 733/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 874.2513 - val_loss: 881.5152\n",
      "Epoch 734/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 871.8950 - val_loss: 888.6247\n",
      "Epoch 735/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 873.3978 - val_loss: 878.0152\n",
      "Epoch 736/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 869.8616 - val_loss: 877.7416\n",
      "Epoch 737/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 872.3376 - val_loss: 879.0820\n",
      "Epoch 738/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 871.3451 - val_loss: 883.6895\n",
      "Epoch 739/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 870.6090 - val_loss: 883.6120\n",
      "Epoch 740/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 871.6958 - val_loss: 882.7399\n",
      "Epoch 741/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 872.9717 - val_loss: 880.6962\n",
      "Epoch 742/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 873.3881 - val_loss: 881.2734\n",
      "Epoch 743/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 870.8750 - val_loss: 881.1754\n",
      "Epoch 744/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 872.0741 - val_loss: 890.5107\n",
      "Epoch 745/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 871.2264 - val_loss: 886.6782\n",
      "Epoch 746/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 871.0660 - val_loss: 882.0101\n",
      "Epoch 747/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 872.0745 - val_loss: 878.2379\n",
      "Epoch 748/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 876.3222 - val_loss: 878.9260\n",
      "Epoch 749/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 870.9282 - val_loss: 878.4270\n",
      "Epoch 750/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 872.4179 - val_loss: 884.8151\n",
      "Epoch 751/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 871.5779 - val_loss: 879.0780\n",
      "Epoch 752/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 871.3165 - val_loss: 887.2814\n",
      "Epoch 753/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 873.0253 - val_loss: 879.5755\n",
      "Epoch 754/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 870.8741 - val_loss: 884.4044\n",
      "Epoch 755/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 871.7665 - val_loss: 884.5969\n",
      "Epoch 756/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 871.7305 - val_loss: 886.2200\n",
      "Epoch 757/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 872.5883 - val_loss: 879.4742\n",
      "Epoch 758/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 870.6096 - val_loss: 880.9972\n",
      "Epoch 759/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 872.5537 - val_loss: 879.4064\n",
      "Epoch 760/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 872.6697 - val_loss: 877.8012\n",
      "Epoch 761/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 870.8692 - val_loss: 891.3024\n",
      "Epoch 762/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 873.4267 - val_loss: 890.5031\n",
      "Epoch 763/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 870.5983 - val_loss: 880.6396\n",
      "Epoch 764/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 872.7247 - val_loss: 882.2789\n",
      "Epoch 765/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 869.5240 - val_loss: 879.0740\n",
      "Epoch 766/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.4761 - val_loss: 881.7782\n",
      "Epoch 767/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 870.3987 - val_loss: 876.5967\n",
      "Epoch 768/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 872.9522 - val_loss: 884.6745\n",
      "Epoch 769/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 884.5110 - val_loss: 880.8589\n",
      "Epoch 770/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 869.8961 - val_loss: 879.7700\n",
      "Epoch 771/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 872.6847 - val_loss: 879.5710\n",
      "Epoch 772/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 871.9914 - val_loss: 877.9901\n",
      "Epoch 773/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 870.1777 - val_loss: 876.9439\n",
      "Epoch 774/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 871.9249 - val_loss: 895.9268\n",
      "Epoch 775/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 872.8203 - val_loss: 878.7394\n",
      "Epoch 776/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 871.6420 - val_loss: 876.9850\n",
      "Epoch 777/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 871.6995 - val_loss: 877.6472\n",
      "Epoch 778/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 870.4791 - val_loss: 886.9983\n",
      "Epoch 779/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 870.8553 - val_loss: 876.7128\n",
      "Epoch 780/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 870.1625 - val_loss: 886.1164\n",
      "Epoch 781/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 869.7441 - val_loss: 878.2216\n",
      "Epoch 782/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 871.0399 - val_loss: 884.0433\n",
      "Epoch 783/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 871.9843 - val_loss: 878.1722\n",
      "Epoch 784/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 871.0731 - val_loss: 878.2428\n",
      "Epoch 785/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 872.7556 - val_loss: 882.5068\n",
      "Epoch 786/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 870.3488 - val_loss: 883.7789\n",
      "Epoch 787/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 873.0321 - val_loss: 877.9563\n",
      "Epoch 788/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 871.7502 - val_loss: 889.0263\n",
      "Epoch 789/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 872.1740 - val_loss: 881.3761\n",
      "Epoch 790/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 871.0479 - val_loss: 881.9748\n",
      "Epoch 791/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 869.5087 - val_loss: 878.1151\n",
      "Epoch 792/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 872.1088 - val_loss: 880.0401\n",
      "Epoch 793/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 871.7612 - val_loss: 877.9686\n",
      "Epoch 794/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 869.3837 - val_loss: 879.8612\n",
      "Epoch 795/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 870.9954 - val_loss: 889.3128\n",
      "Epoch 796/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 872.8462 - val_loss: 881.4412\n",
      "Epoch 797/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 873.2056 - val_loss: 878.7634\n",
      "Epoch 798/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 883.2017 - val_loss: 883.8682\n",
      "Epoch 799/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 874.3221 - val_loss: 894.3652\n",
      "Epoch 800/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 874.0482 - val_loss: 882.0282\n",
      "Epoch 801/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 876.2189 - val_loss: 881.6237\n",
      "Epoch 802/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 870.4255 - val_loss: 879.0752\n",
      "Epoch 803/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 870.3589 - val_loss: 879.5748\n",
      "Epoch 804/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 870.0352 - val_loss: 882.2918\n",
      "Epoch 805/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 872.3555 - val_loss: 879.9375\n",
      "Epoch 806/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 870.5542 - val_loss: 879.4847\n",
      "Epoch 807/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 874.2314 - val_loss: 877.8915\n",
      "Epoch 808/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 870.1729 - val_loss: 878.7241\n",
      "Epoch 809/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 869.5170 - val_loss: 879.0780\n",
      "Epoch 810/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 871.6645 - val_loss: 880.9007\n",
      "Epoch 811/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 870.3394 - val_loss: 883.6365\n",
      "Epoch 812/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 875.5728 - val_loss: 883.7840\n",
      "Epoch 813/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 870.5186 - val_loss: 880.4852\n",
      "Epoch 814/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 869.4999 - val_loss: 881.8024\n",
      "Epoch 815/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 870.6978 - val_loss: 880.8047\n",
      "Epoch 816/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 872.0379 - val_loss: 892.5273\n",
      "Epoch 817/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 870.2416 - val_loss: 882.3017\n",
      "Epoch 818/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 869.5497 - val_loss: 882.8868\n",
      "Epoch 819/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 870.4504 - val_loss: 883.5352\n",
      "Epoch 820/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 872.1681 - val_loss: 882.0312\n",
      "Epoch 821/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 870.8498 - val_loss: 893.8694\n",
      "Epoch 822/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 871.1802 - val_loss: 889.7683\n",
      "Epoch 823/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 872.2061 - val_loss: 879.3142\n",
      "Epoch 824/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 869.5352 - val_loss: 878.4708\n",
      "Epoch 825/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 871.3095 - val_loss: 882.7689\n",
      "Epoch 826/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 869.7313 - val_loss: 888.4038\n",
      "Epoch 827/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 872.4378 - val_loss: 880.5452\n",
      "Epoch 828/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 869.5149 - val_loss: 878.4797\n",
      "Epoch 829/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 870.6965 - val_loss: 880.0665\n",
      "Epoch 830/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 868.4200 - val_loss: 879.3357\n",
      "Epoch 831/1300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 872.2116 - val_loss: 880.0439\n",
      "Epoch 832/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 869.6464 - val_loss: 879.3840\n",
      "Epoch 833/1300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 870.9424 - val_loss: 882.8705\n",
      "Epoch 834/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 869.3747 - val_loss: 880.8377\n",
      "Epoch 835/1300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 870.1884 - val_loss: 890.8939\n",
      "Epoch 836/1300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 874.5872 - val_loss: 877.8031\n",
      "Epoch 837/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 870.1608 - val_loss: 888.1024\n",
      "Epoch 838/1300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 874.5883 - val_loss: 887.8373\n",
      "Epoch 839/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 869.7210 - val_loss: 880.1628\n",
      "Epoch 840/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 872.4678 - val_loss: 877.5944\n",
      "Epoch 841/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 871.3116 - val_loss: 888.1362\n",
      "Epoch 842/1300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 870.5963 - val_loss: 878.6872\n",
      "Epoch 843/1300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 871.9932 - val_loss: 876.8541\n",
      "Epoch 844/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 870.1721 - val_loss: 877.1648\n",
      "Epoch 845/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.6127 - val_loss: 880.2036\n",
      "Epoch 846/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 872.6253 - val_loss: 877.4974\n",
      "Epoch 847/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.9426 - val_loss: 878.9854\n",
      "Epoch 848/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 880.9284 - val_loss: 880.0967\n",
      "Epoch 849/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 870.2494 - val_loss: 877.9547\n",
      "Epoch 850/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 872.4608 - val_loss: 883.1568\n",
      "Epoch 851/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 871.9891 - val_loss: 878.3622\n",
      "Epoch 852/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 870.3980 - val_loss: 877.6542\n",
      "Epoch 853/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.0342 - val_loss: 877.8080\n",
      "Epoch 854/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 870.4440 - val_loss: 876.9936\n",
      "Epoch 855/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.7621 - val_loss: 878.6475\n",
      "Epoch 856/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 870.0067 - val_loss: 889.4750\n",
      "Epoch 857/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 870.7169 - val_loss: 884.4543\n",
      "Epoch 858/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 872.5459 - val_loss: 885.6505\n",
      "Epoch 859/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 872.6498 - val_loss: 878.8295\n",
      "Epoch 860/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 872.6489 - val_loss: 877.7415\n",
      "Epoch 861/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 871.9542 - val_loss: 877.4003\n",
      "Epoch 862/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 869.7103 - val_loss: 882.3576\n",
      "Epoch 863/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 870.7985 - val_loss: 886.3777\n",
      "Epoch 864/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 870.9573 - val_loss: 883.2323\n",
      "Epoch 865/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 869.5542 - val_loss: 877.9319\n",
      "Epoch 866/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.7847 - val_loss: 879.9917\n",
      "Epoch 867/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 868.9689 - val_loss: 876.5649\n",
      "Epoch 868/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 867.4985 - val_loss: 878.7748\n",
      "Epoch 869/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 871.0825 - val_loss: 879.4749\n",
      "Epoch 870/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 869.7567 - val_loss: 878.7770\n",
      "Epoch 871/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 870.3245 - val_loss: 878.6396\n",
      "Epoch 872/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 869.0082 - val_loss: 878.2759\n",
      "Epoch 873/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 871.4059 - val_loss: 883.1492\n",
      "Epoch 874/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 868.0012 - val_loss: 882.1744\n",
      "Epoch 875/1300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 870.2244 - val_loss: 877.4060\n",
      "Epoch 876/1300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 869.0475 - val_loss: 877.3475\n",
      "Epoch 877/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 870.0007 - val_loss: 890.4409\n",
      "Epoch 878/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 870.3409 - val_loss: 879.5229\n",
      "Epoch 879/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 867.8754 - val_loss: 879.9716\n",
      "Epoch 880/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 872.3840 - val_loss: 876.7910\n",
      "Epoch 881/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 873.0681 - val_loss: 876.4735\n",
      "Epoch 882/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 869.5637 - val_loss: 884.3393\n",
      "Epoch 883/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 867.5330 - val_loss: 881.2535\n",
      "Epoch 884/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 873.5605 - val_loss: 878.7943\n",
      "Epoch 885/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 870.2857 - val_loss: 881.3813\n",
      "Epoch 886/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 868.5184 - val_loss: 894.5611\n",
      "Epoch 887/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 870.6574 - val_loss: 880.0032\n",
      "Epoch 888/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.9097 - val_loss: 878.4342\n",
      "Epoch 889/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.5001 - val_loss: 882.0792\n",
      "Epoch 890/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.0248 - val_loss: 877.6030\n",
      "Epoch 891/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.3142 - val_loss: 886.1643\n",
      "Epoch 892/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 870.3865 - val_loss: 876.4104\n",
      "Epoch 893/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.4971 - val_loss: 879.7747\n",
      "Epoch 894/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.6965 - val_loss: 881.1989\n",
      "Epoch 895/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 875.2560 - val_loss: 876.8038\n",
      "Epoch 896/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 869.9840 - val_loss: 879.0103\n",
      "Epoch 897/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.9579 - val_loss: 878.1443\n",
      "Epoch 898/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.8995 - val_loss: 878.4367\n",
      "Epoch 899/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.6240 - val_loss: 879.1800\n",
      "Epoch 900/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 872.8245 - val_loss: 878.2997\n",
      "Epoch 901/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 869.2853 - val_loss: 881.4180\n",
      "Epoch 902/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 871.2887 - val_loss: 876.8211\n",
      "Epoch 903/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 869.2752 - val_loss: 877.5570\n",
      "Epoch 904/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 869.8619 - val_loss: 876.7906\n",
      "Epoch 905/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 876.8471 - val_loss: 892.6584\n",
      "Epoch 906/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 874.8709 - val_loss: 877.5026\n",
      "Epoch 907/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.6294 - val_loss: 884.1344\n",
      "Epoch 908/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.2816 - val_loss: 879.6382\n",
      "Epoch 909/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.4393 - val_loss: 884.6762\n",
      "Epoch 910/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 870.1991 - val_loss: 882.6899\n",
      "Epoch 911/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.6849 - val_loss: 880.7969\n",
      "Epoch 912/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 870.5939 - val_loss: 888.4926\n",
      "Epoch 913/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 871.0364 - val_loss: 924.2126\n",
      "Epoch 914/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 880.4855 - val_loss: 883.4229\n",
      "Epoch 915/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 869.6572 - val_loss: 878.8121\n",
      "Epoch 916/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 870.2968 - val_loss: 880.1880\n",
      "Epoch 917/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 870.5983 - val_loss: 879.1166\n",
      "Epoch 918/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 867.5009 - val_loss: 878.7719\n",
      "Epoch 919/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 870.2083 - val_loss: 878.8786\n",
      "Epoch 920/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 868.8471 - val_loss: 876.6124\n",
      "Epoch 921/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 867.5406 - val_loss: 882.4714\n",
      "Epoch 922/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 867.3347 - val_loss: 877.2779\n",
      "Epoch 923/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 869.2795 - val_loss: 878.4165\n",
      "Epoch 924/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 867.9494 - val_loss: 880.5009\n",
      "Epoch 925/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 869.0247 - val_loss: 877.2236\n",
      "Epoch 926/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 870.3280 - val_loss: 881.8629\n",
      "Epoch 927/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 869.5749 - val_loss: 880.7980\n",
      "Epoch 928/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 868.0340 - val_loss: 878.0720\n",
      "Epoch 929/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 868.9630 - val_loss: 879.9038\n",
      "Epoch 930/1300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 869.8268 - val_loss: 880.5308\n",
      "Epoch 931/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 870.3093 - val_loss: 877.7325\n",
      "Epoch 932/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 870.2433 - val_loss: 881.2109\n",
      "Epoch 933/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.2960 - val_loss: 886.2595\n",
      "Epoch 934/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.5463 - val_loss: 878.2974\n",
      "Epoch 935/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 873.3701 - val_loss: 884.8308\n",
      "Epoch 936/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 872.1758 - val_loss: 879.1038\n",
      "Epoch 937/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.3834 - val_loss: 885.6573\n",
      "Epoch 938/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 874.9095 - val_loss: 877.7867\n",
      "Epoch 939/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 870.8318 - val_loss: 876.2803\n",
      "Epoch 940/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 871.7535 - val_loss: 885.7677\n",
      "Epoch 941/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 872.2350 - val_loss: 879.7329\n",
      "Epoch 942/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.2716 - val_loss: 876.5383\n",
      "Epoch 943/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.3322 - val_loss: 883.6057\n",
      "Epoch 944/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.6904 - val_loss: 880.7904\n",
      "Epoch 945/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 870.2112 - val_loss: 881.7460\n",
      "Epoch 946/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.9094 - val_loss: 893.0082\n",
      "Epoch 947/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 872.3183 - val_loss: 878.2731\n",
      "Epoch 948/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 869.4639 - val_loss: 882.1073\n",
      "Epoch 949/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 869.5708 - val_loss: 882.0062\n",
      "Epoch 950/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.5648 - val_loss: 880.0078\n",
      "Epoch 951/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 869.0344 - val_loss: 878.3995\n",
      "Epoch 952/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 869.2667 - val_loss: 882.8328\n",
      "Epoch 953/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.1407 - val_loss: 881.6539\n",
      "Epoch 954/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.1277 - val_loss: 881.6549\n",
      "Epoch 955/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.3379 - val_loss: 878.6575\n",
      "Epoch 956/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 870.9677 - val_loss: 877.1401\n",
      "Epoch 957/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.7559 - val_loss: 880.1980\n",
      "Epoch 958/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.7803 - val_loss: 884.8887\n",
      "Epoch 959/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 871.7690 - val_loss: 876.6091\n",
      "Epoch 960/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 869.8074 - val_loss: 876.8700\n",
      "Epoch 961/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 867.4271 - val_loss: 879.2874\n",
      "Epoch 962/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 868.8701 - val_loss: 877.8744\n",
      "Epoch 963/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 868.0023 - val_loss: 878.1808\n",
      "Epoch 964/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 868.5106 - val_loss: 880.6514\n",
      "Epoch 965/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 868.6396 - val_loss: 878.1627\n",
      "Epoch 966/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 871.0259 - val_loss: 878.6943\n",
      "Epoch 967/1300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 868.7524 - val_loss: 879.0256\n",
      "Epoch 968/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 870.5438 - val_loss: 877.8788\n",
      "Epoch 969/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 869.8864 - val_loss: 878.9428\n",
      "Epoch 970/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 869.7344 - val_loss: 879.1348\n",
      "Epoch 971/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 872.8251 - val_loss: 885.1358\n",
      "Epoch 972/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 868.2684 - val_loss: 878.4151\n",
      "Epoch 973/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 867.9250 - val_loss: 877.4286\n",
      "Epoch 974/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 868.0144 - val_loss: 880.2410\n",
      "Epoch 975/1300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 867.4199 - val_loss: 879.8451\n",
      "Epoch 976/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.2387 - val_loss: 879.8112\n",
      "Epoch 977/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 866.8942 - val_loss: 879.4540\n",
      "Epoch 978/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.9006 - val_loss: 882.4858\n",
      "Epoch 979/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.2472 - val_loss: 883.2472\n",
      "Epoch 980/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.4948 - val_loss: 881.4517\n",
      "Epoch 981/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.1806 - val_loss: 880.6871\n",
      "Epoch 982/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.3400 - val_loss: 879.5439\n",
      "Epoch 983/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 867.4322 - val_loss: 881.3331\n",
      "Epoch 984/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.8798 - val_loss: 879.5344\n",
      "Epoch 985/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.9607 - val_loss: 878.5906\n",
      "Epoch 986/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.5358 - val_loss: 879.9333\n",
      "Epoch 987/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 870.7253 - val_loss: 880.6584\n",
      "Epoch 988/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 871.8175 - val_loss: 877.9548\n",
      "Epoch 989/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.4716 - val_loss: 879.7589\n",
      "Epoch 990/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 866.8032 - val_loss: 879.6521\n",
      "Epoch 991/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.1146 - val_loss: 880.2740\n",
      "Epoch 992/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 875.2864 - val_loss: 889.8913\n",
      "Epoch 993/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.8956 - val_loss: 885.5187\n",
      "Epoch 994/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 869.0640 - val_loss: 876.7521\n",
      "Epoch 995/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 866.7283 - val_loss: 883.2615\n",
      "Epoch 996/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.9834 - val_loss: 884.3393\n",
      "Epoch 997/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 866.9091 - val_loss: 878.2141\n",
      "Epoch 998/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 875.2356 - val_loss: 880.9601\n",
      "Epoch 999/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.0341 - val_loss: 896.4669\n",
      "Epoch 1000/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.4497 - val_loss: 879.0057\n",
      "Epoch 1001/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.0858 - val_loss: 876.5248\n",
      "Epoch 1002/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.9465 - val_loss: 877.6530\n",
      "Epoch 1003/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 866.1797 - val_loss: 881.6112\n",
      "Epoch 1004/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 866.8239 - val_loss: 878.6713\n",
      "Epoch 1005/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 867.7864 - val_loss: 878.9349\n",
      "Epoch 1006/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 867.3314 - val_loss: 880.6219\n",
      "Epoch 1007/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 869.2397 - val_loss: 882.7847\n",
      "Epoch 1008/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 868.1973 - val_loss: 895.3323\n",
      "Epoch 1009/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 868.8462 - val_loss: 878.2477\n",
      "Epoch 1010/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 867.7277 - val_loss: 877.5635\n",
      "Epoch 1011/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 867.5341 - val_loss: 881.2502\n",
      "Epoch 1012/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 869.7600 - val_loss: 885.1152\n",
      "Epoch 1013/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 868.5408 - val_loss: 879.0173\n",
      "Epoch 1014/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 868.7698 - val_loss: 880.8835\n",
      "Epoch 1015/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 868.2474 - val_loss: 893.6775\n",
      "Epoch 1016/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 868.9485 - val_loss: 878.9987\n",
      "Epoch 1017/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 866.1584 - val_loss: 877.8354\n",
      "Epoch 1018/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 868.2639 - val_loss: 878.7645\n",
      "Epoch 1019/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 870.1573 - val_loss: 882.3484\n",
      "Epoch 1020/1300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 869.9820 - val_loss: 878.0686\n",
      "Epoch 1021/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 868.0009 - val_loss: 876.7509\n",
      "Epoch 1022/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 869.6829 - val_loss: 883.1155\n",
      "Epoch 1023/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 866.5306 - val_loss: 879.0589\n",
      "Epoch 1024/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 866.9198 - val_loss: 877.0700\n",
      "Epoch 1025/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 868.0432 - val_loss: 877.5954\n",
      "Epoch 1026/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.2832 - val_loss: 890.2138\n",
      "Epoch 1027/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.3444 - val_loss: 880.7720\n",
      "Epoch 1028/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 866.4359 - val_loss: 882.9620\n",
      "Epoch 1029/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.6173 - val_loss: 879.7029\n",
      "Epoch 1030/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 869.1834 - val_loss: 878.4390\n",
      "Epoch 1031/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 872.3525 - val_loss: 880.5552\n",
      "Epoch 1032/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.7339 - val_loss: 879.3008\n",
      "Epoch 1033/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.5454 - val_loss: 878.6094\n",
      "Epoch 1034/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 871.1825 - val_loss: 876.6572\n",
      "Epoch 1035/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 872.1206 - val_loss: 886.2778\n",
      "Epoch 1036/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.8521 - val_loss: 878.4402\n",
      "Epoch 1037/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.0973 - val_loss: 878.4778\n",
      "Epoch 1038/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 866.7028 - val_loss: 881.9047\n",
      "Epoch 1039/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.0870 - val_loss: 877.8333\n",
      "Epoch 1040/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.3561 - val_loss: 882.5781\n",
      "Epoch 1041/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 870.7720 - val_loss: 888.6068\n",
      "Epoch 1042/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.1552 - val_loss: 878.9183\n",
      "Epoch 1043/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 866.1107 - val_loss: 879.2509\n",
      "Epoch 1044/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.8646 - val_loss: 875.8843\n",
      "Epoch 1045/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.2160 - val_loss: 889.6666\n",
      "Epoch 1046/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.4963 - val_loss: 878.8825\n",
      "Epoch 1047/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 869.6449 - val_loss: 879.4287\n",
      "Epoch 1048/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 866.0460 - val_loss: 881.8069\n",
      "Epoch 1049/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.1973 - val_loss: 880.9191\n",
      "Epoch 1050/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 868.6369 - val_loss: 877.6824\n",
      "Epoch 1051/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 870.1719 - val_loss: 881.3121\n",
      "Epoch 1052/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 867.7148 - val_loss: 878.6431\n",
      "Epoch 1053/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 866.3105 - val_loss: 878.1443\n",
      "Epoch 1054/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 867.0995 - val_loss: 876.0868\n",
      "Epoch 1055/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 877.3026 - val_loss: 876.2219\n",
      "Epoch 1056/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 868.5096 - val_loss: 878.1100\n",
      "Epoch 1057/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 867.1322 - val_loss: 884.8811\n",
      "Epoch 1058/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 873.0298 - val_loss: 898.3301\n",
      "Epoch 1059/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 867.5892 - val_loss: 879.9287\n",
      "Epoch 1060/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 868.3502 - val_loss: 878.7253\n",
      "Epoch 1061/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 867.1379 - val_loss: 881.9921\n",
      "Epoch 1062/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 868.5560 - val_loss: 878.5563\n",
      "Epoch 1063/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 868.6595 - val_loss: 875.5887\n",
      "Epoch 1064/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 868.1261 - val_loss: 879.6286\n",
      "Epoch 1065/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 867.3580 - val_loss: 885.5550\n",
      "Epoch 1066/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 870.8974 - val_loss: 877.1821\n",
      "Epoch 1067/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.8946 - val_loss: 878.4164\n",
      "Epoch 1068/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.9354 - val_loss: 883.9883\n",
      "Epoch 1069/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.3271 - val_loss: 876.2404\n",
      "Epoch 1070/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 869.7990 - val_loss: 879.2169\n",
      "Epoch 1071/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 869.1146 - val_loss: 876.2966\n",
      "Epoch 1072/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 866.4541 - val_loss: 877.5117\n",
      "Epoch 1073/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.7521 - val_loss: 879.8992\n",
      "Epoch 1074/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 869.4444 - val_loss: 880.3661\n",
      "Epoch 1075/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 870.9857 - val_loss: 877.7808\n",
      "Epoch 1076/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 870.0405 - val_loss: 896.0969\n",
      "Epoch 1077/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 869.0785 - val_loss: 880.2915\n",
      "Epoch 1078/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.2490 - val_loss: 890.8531\n",
      "Epoch 1079/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.3825 - val_loss: 881.2296\n",
      "Epoch 1080/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 869.2899 - val_loss: 890.2787\n",
      "Epoch 1081/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 866.7214 - val_loss: 881.0204\n",
      "Epoch 1082/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 870.3387 - val_loss: 878.0062\n",
      "Epoch 1083/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 867.2899 - val_loss: 878.6068\n",
      "Epoch 1084/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 866.5354 - val_loss: 878.2264\n",
      "Epoch 1085/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.2476 - val_loss: 879.2992\n",
      "Epoch 1086/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.4871 - val_loss: 880.6582\n",
      "Epoch 1087/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 871.1641 - val_loss: 878.9480\n",
      "Epoch 1088/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.0035 - val_loss: 878.6498\n",
      "Epoch 1089/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 871.9922 - val_loss: 884.8975\n",
      "Epoch 1090/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 871.7500 - val_loss: 879.2528\n",
      "Epoch 1091/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.2246 - val_loss: 888.3299\n",
      "Epoch 1092/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.2435 - val_loss: 882.3329\n",
      "Epoch 1093/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 866.9435 - val_loss: 877.2971\n",
      "Epoch 1094/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.0530 - val_loss: 878.5397\n",
      "Epoch 1095/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 868.0326 - val_loss: 880.4493\n",
      "Epoch 1096/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 872.0941 - val_loss: 883.9042\n",
      "Epoch 1097/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 866.5008 - val_loss: 878.7001\n",
      "Epoch 1098/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.1333 - val_loss: 881.1269\n",
      "Epoch 1099/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 870.1187 - val_loss: 888.9844\n",
      "Epoch 1100/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 876.8148 - val_loss: 876.7870\n",
      "Epoch 1101/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 867.1280 - val_loss: 878.0591\n",
      "Epoch 1102/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 866.2779 - val_loss: 893.3035\n",
      "Epoch 1103/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 868.7075 - val_loss: 878.8032\n",
      "Epoch 1104/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 868.0937 - val_loss: 880.7564\n",
      "Epoch 1105/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.5414 - val_loss: 879.1210\n",
      "Epoch 1106/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 867.4401 - val_loss: 877.6337\n",
      "Epoch 1107/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 868.4833 - val_loss: 878.6202\n",
      "Epoch 1108/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 868.2313 - val_loss: 876.1514\n",
      "Epoch 1109/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 870.7073 - val_loss: 883.5845\n",
      "Epoch 1110/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 871.0566 - val_loss: 878.5095\n",
      "Epoch 1111/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 867.0463 - val_loss: 878.0759\n",
      "Epoch 1112/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 865.6461 - val_loss: 879.4561\n",
      "Epoch 1113/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 866.6972 - val_loss: 885.9012\n",
      "Epoch 1114/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 869.7454 - val_loss: 890.4775\n",
      "Epoch 1115/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 870.8860 - val_loss: 878.8314\n",
      "Epoch 1116/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.4716 - val_loss: 877.6636\n",
      "Epoch 1117/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 867.2100 - val_loss: 877.8345\n",
      "Epoch 1118/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.4547 - val_loss: 881.7571\n",
      "Epoch 1119/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 870.5463 - val_loss: 899.5406\n",
      "Epoch 1120/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 873.5892 - val_loss: 880.2969\n",
      "Epoch 1121/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 869.5688 - val_loss: 878.2804\n",
      "Epoch 1122/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.8424 - val_loss: 884.1085\n",
      "Epoch 1123/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.1757 - val_loss: 879.7645\n",
      "Epoch 1124/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.6290 - val_loss: 876.9794\n",
      "Epoch 1125/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.9008 - val_loss: 878.6829\n",
      "Epoch 1126/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.9513 - val_loss: 882.3405\n",
      "Epoch 1127/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.1961 - val_loss: 880.8622\n",
      "Epoch 1128/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 866.9023 - val_loss: 881.6270\n",
      "Epoch 1129/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.2197 - val_loss: 879.9509\n",
      "Epoch 1130/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 866.6421 - val_loss: 878.8460\n",
      "Epoch 1131/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 866.8876 - val_loss: 876.0702\n",
      "Epoch 1132/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 868.4682 - val_loss: 877.5712\n",
      "Epoch 1133/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 866.2691 - val_loss: 877.4859\n",
      "Epoch 1134/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 868.1095 - val_loss: 880.6946\n",
      "Epoch 1135/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 866.1328 - val_loss: 879.1609\n",
      "Epoch 1136/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 873.3869 - val_loss: 895.5909\n",
      "Epoch 1137/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.3979 - val_loss: 878.4448\n",
      "Epoch 1138/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.7954 - val_loss: 890.1498\n",
      "Epoch 1139/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.5002 - val_loss: 878.4668\n",
      "Epoch 1140/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.8288 - val_loss: 881.1604\n",
      "Epoch 1141/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 866.9478 - val_loss: 878.8230\n",
      "Epoch 1142/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 866.2790 - val_loss: 878.9755\n",
      "Epoch 1143/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 866.1529 - val_loss: 880.0219\n",
      "Epoch 1144/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 865.9828 - val_loss: 880.3424\n",
      "Epoch 1145/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 866.8483 - val_loss: 879.4202\n",
      "Epoch 1146/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 865.8186 - val_loss: 878.8024\n",
      "Epoch 1147/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.6265 - val_loss: 879.7438\n",
      "Epoch 1148/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 868.6096 - val_loss: 877.7596\n",
      "Epoch 1149/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 866.7780 - val_loss: 879.2841\n",
      "Epoch 1150/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 866.3580 - val_loss: 880.2993\n",
      "Epoch 1151/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 868.9587 - val_loss: 884.4462\n",
      "Epoch 1152/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 868.1851 - val_loss: 878.6129\n",
      "Epoch 1153/1300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 867.5447 - val_loss: 878.7553\n",
      "Epoch 1154/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 865.9124 - val_loss: 878.8799\n",
      "Epoch 1155/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 866.9601 - val_loss: 877.1459\n",
      "Epoch 1156/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 868.4705 - val_loss: 881.0031\n",
      "Epoch 1157/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 867.5249 - val_loss: 879.1833\n",
      "Epoch 1158/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 865.3806 - val_loss: 880.6261\n",
      "Epoch 1159/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.7026 - val_loss: 877.5506\n",
      "Epoch 1160/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 874.8343 - val_loss: 875.5937\n",
      "Epoch 1161/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.3874 - val_loss: 888.9709\n",
      "Epoch 1162/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 866.2870 - val_loss: 885.1800\n",
      "Epoch 1163/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.1599 - val_loss: 888.6351\n",
      "Epoch 1164/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 866.9092 - val_loss: 883.9139\n",
      "Epoch 1165/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 866.6376 - val_loss: 879.9446\n",
      "Epoch 1166/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.3077 - val_loss: 876.5392\n",
      "Epoch 1167/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 866.5945 - val_loss: 879.1918\n",
      "Epoch 1168/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 866.1275 - val_loss: 881.0849\n",
      "Epoch 1169/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.3508 - val_loss: 881.7396\n",
      "Epoch 1170/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 868.2114 - val_loss: 877.9351\n",
      "Epoch 1171/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 868.3518 - val_loss: 881.7710\n",
      "Epoch 1172/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 872.8469 - val_loss: 877.4203\n",
      "Epoch 1173/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 866.4521 - val_loss: 879.8841\n",
      "Epoch 1174/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 869.4823 - val_loss: 884.2915\n",
      "Epoch 1175/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 866.6472 - val_loss: 876.1921\n",
      "Epoch 1176/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.8356 - val_loss: 877.8915\n",
      "Epoch 1177/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.6736 - val_loss: 875.9416\n",
      "Epoch 1178/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.5444 - val_loss: 882.0976\n",
      "Epoch 1179/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.4624 - val_loss: 879.0204\n",
      "Epoch 1180/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.7544 - val_loss: 881.1510\n",
      "Epoch 1181/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.0180 - val_loss: 879.1852\n",
      "Epoch 1182/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 873.3021 - val_loss: 878.8289\n",
      "Epoch 1183/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 866.8595 - val_loss: 879.3665\n",
      "Epoch 1184/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 866.6038 - val_loss: 886.1287\n",
      "Epoch 1185/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 866.8795 - val_loss: 891.3776\n",
      "Epoch 1186/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.6656 - val_loss: 877.7724\n",
      "Epoch 1187/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 869.6580 - val_loss: 876.9080\n",
      "Epoch 1188/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 867.3356 - val_loss: 879.0067\n",
      "Epoch 1189/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 866.3493 - val_loss: 880.5565\n",
      "Epoch 1190/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 867.8304 - val_loss: 879.0427\n",
      "Epoch 1191/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 867.9138 - val_loss: 877.3715\n",
      "Epoch 1192/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 867.9279 - val_loss: 880.8123\n",
      "Epoch 1193/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 864.7283 - val_loss: 877.9860\n",
      "Epoch 1194/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 869.4059 - val_loss: 878.2267\n",
      "Epoch 1195/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 867.8069 - val_loss: 876.9619\n",
      "Epoch 1196/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 868.5352 - val_loss: 879.1378\n",
      "Epoch 1197/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 866.2516 - val_loss: 878.5159\n",
      "Epoch 1198/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 866.8571 - val_loss: 878.4647\n",
      "Epoch 1199/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 866.7153 - val_loss: 882.3407\n",
      "Epoch 1200/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 867.0607 - val_loss: 877.5815\n",
      "Epoch 1201/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 866.9289 - val_loss: 882.2856\n",
      "Epoch 1202/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 868.7533 - val_loss: 886.2635\n",
      "Epoch 1203/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 867.9824 - val_loss: 877.2252\n",
      "Epoch 1204/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 869.0671 - val_loss: 877.8853\n",
      "Epoch 1205/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.4013 - val_loss: 880.7363\n",
      "Epoch 1206/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.8365 - val_loss: 877.0988\n",
      "Epoch 1207/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 866.6542 - val_loss: 882.0647\n",
      "Epoch 1208/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.5223 - val_loss: 884.8162\n",
      "Epoch 1209/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.3575 - val_loss: 880.3232\n",
      "Epoch 1210/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 867.4394 - val_loss: 895.0789\n",
      "Epoch 1211/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 867.6389 - val_loss: 879.3345\n",
      "Epoch 1212/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 870.0900 - val_loss: 881.6099\n",
      "Epoch 1213/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.4501 - val_loss: 876.6747\n",
      "Epoch 1214/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.0400 - val_loss: 876.6921\n",
      "Epoch 1215/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 866.8545 - val_loss: 878.4524\n",
      "Epoch 1216/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.9042 - val_loss: 877.2170\n",
      "Epoch 1217/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 866.3093 - val_loss: 881.3225\n",
      "Epoch 1218/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 866.4902 - val_loss: 878.4790\n",
      "Epoch 1219/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 866.7073 - val_loss: 877.3054\n",
      "Epoch 1220/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 865.7695 - val_loss: 878.6325\n",
      "Epoch 1221/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 869.6302 - val_loss: 878.4182\n",
      "Epoch 1222/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 869.2950 - val_loss: 877.6334\n",
      "Epoch 1223/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 866.4559 - val_loss: 876.8071\n",
      "Epoch 1224/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 866.4349 - val_loss: 881.2558\n",
      "Epoch 1225/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.1724 - val_loss: 894.0868\n",
      "Epoch 1226/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 871.6843 - val_loss: 877.2101\n",
      "Epoch 1227/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.4839 - val_loss: 877.1320\n",
      "Epoch 1228/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 865.9660 - val_loss: 897.3079\n",
      "Epoch 1229/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.3539 - val_loss: 877.6136\n",
      "Epoch 1230/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 867.4549 - val_loss: 878.7393\n",
      "Epoch 1231/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.7634 - val_loss: 883.5164\n",
      "Epoch 1232/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.4899 - val_loss: 923.2186\n",
      "Epoch 1233/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 878.3958 - val_loss: 884.6487\n",
      "Epoch 1234/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 869.3416 - val_loss: 877.5344\n",
      "Epoch 1235/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 867.6895 - val_loss: 876.0514\n",
      "Epoch 1236/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 865.3934 - val_loss: 878.2604\n",
      "Epoch 1237/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 867.7692 - val_loss: 880.2657\n",
      "Epoch 1238/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 868.6628 - val_loss: 876.5049\n",
      "Epoch 1239/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 867.1133 - val_loss: 881.2814\n",
      "Epoch 1240/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 866.5223 - val_loss: 876.6440\n",
      "Epoch 1241/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 865.2657 - val_loss: 886.7596\n",
      "Epoch 1242/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 868.3843 - val_loss: 880.5141\n",
      "Epoch 1243/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 866.2709 - val_loss: 878.0787\n",
      "Epoch 1244/1300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 869.1985 - val_loss: 877.2325\n",
      "Epoch 1245/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 869.2804 - val_loss: 877.4991\n",
      "Epoch 1246/1300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 870.5805 - val_loss: 877.3638\n",
      "Epoch 1247/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 870.5346 - val_loss: 879.0803\n",
      "Epoch 1248/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 867.2624 - val_loss: 883.3133\n",
      "Epoch 1249/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 865.6500 - val_loss: 880.3952\n",
      "Epoch 1250/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 868.7944 - val_loss: 878.5566\n",
      "Epoch 1251/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 869.8664 - val_loss: 886.6500\n",
      "Epoch 1252/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 866.0984 - val_loss: 876.5771\n",
      "Epoch 1253/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.7889 - val_loss: 888.1577\n",
      "Epoch 1254/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 869.0853 - val_loss: 879.9745\n",
      "Epoch 1255/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 866.4514 - val_loss: 879.7778\n",
      "Epoch 1256/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 871.6108 - val_loss: 884.6180\n",
      "Epoch 1257/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.2137 - val_loss: 877.8474\n",
      "Epoch 1258/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 866.5306 - val_loss: 875.7943\n",
      "Epoch 1259/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.7857 - val_loss: 878.9094\n",
      "Epoch 1260/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 866.6862 - val_loss: 879.7286\n",
      "Epoch 1261/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 871.0035 - val_loss: 876.4464\n",
      "Epoch 1262/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 866.6657 - val_loss: 876.0660\n",
      "Epoch 1263/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 871.2130 - val_loss: 881.0330\n",
      "Epoch 1264/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 867.8252 - val_loss: 877.7783\n",
      "Epoch 1265/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 866.1463 - val_loss: 879.5585\n",
      "Epoch 1266/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.7064 - val_loss: 877.1832\n",
      "Epoch 1267/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 869.4985 - val_loss: 878.5932\n",
      "Epoch 1268/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.8099 - val_loss: 880.0485\n",
      "Epoch 1269/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 865.9918 - val_loss: 878.3059\n",
      "Epoch 1270/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 866.2296 - val_loss: 884.7072\n",
      "Epoch 1271/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 866.9686 - val_loss: 877.0894\n",
      "Epoch 1272/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.5803 - val_loss: 875.7424\n",
      "Epoch 1273/1300\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 869.7983 - val_loss: 877.2062\n",
      "Epoch 1274/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 866.6745 - val_loss: 877.4541\n",
      "Epoch 1275/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.0449 - val_loss: 880.3548\n",
      "Epoch 1276/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 868.9362 - val_loss: 881.0423\n",
      "Epoch 1277/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 866.8044 - val_loss: 876.5490\n",
      "Epoch 1278/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 864.9528 - val_loss: 876.5473\n",
      "Epoch 1279/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 866.9889 - val_loss: 881.6359\n",
      "Epoch 1280/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 867.5422 - val_loss: 876.6000\n",
      "Epoch 1281/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 866.7131 - val_loss: 875.7736\n",
      "Epoch 1282/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 865.7891 - val_loss: 879.2725\n",
      "Epoch 1283/1300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 867.3129 - val_loss: 876.6237\n",
      "Epoch 1284/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 870.4569 - val_loss: 877.8036\n",
      "Epoch 1285/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 869.2257 - val_loss: 877.8874\n",
      "Epoch 1286/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 869.3876 - val_loss: 877.6469\n",
      "Epoch 1287/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 866.7000 - val_loss: 879.9077\n",
      "Epoch 1288/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 866.0212 - val_loss: 881.6487\n",
      "Epoch 1289/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 867.4388 - val_loss: 879.8788\n",
      "Epoch 1290/1300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 867.2236 - val_loss: 881.0419\n",
      "Epoch 1291/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 867.0755 - val_loss: 879.6613\n",
      "Epoch 1292/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 868.1201 - val_loss: 879.8208\n",
      "Epoch 1293/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 866.5458 - val_loss: 880.0674\n",
      "Epoch 1294/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 868.0115 - val_loss: 876.8811\n",
      "Epoch 1295/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 868.8647 - val_loss: 884.7299\n",
      "Epoch 1296/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 866.4832 - val_loss: 877.8001\n",
      "Epoch 1297/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 866.5533 - val_loss: 876.4748\n",
      "Epoch 1298/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 865.7802 - val_loss: 879.0779\n",
      "Epoch 1299/1300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 865.6057 - val_loss: 877.6344\n",
      "Epoch 1300/1300\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 866.2113 - val_loss: 880.6662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7b8cffe95750>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),batch_size=128,epochs=1300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tBqrVlLCQF7g",
    "outputId": "b4676c79-cdba-41f2-874c-07eaac4ff1cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "tahmin=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3lxuQID-THBQ",
    "outputId": "676efa76-0d47-4016-ee7e-bfd9f82545e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015107492583730453"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,tahmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "ce_kn8gMTKHt"
   },
   "outputs": [],
   "source": [
    "loss_df=pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "rXet_3-YTTm0"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-XRa0FMMTQ_u"
   },
   "outputs": [],
   "source": [
    "#SONUÃ‡ Ã‡IKMADI TEKRAR YAPILACAK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0a3bafb7b08d44168524748f38526e70": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1cc1b4a0b2114e70b604e0f1d824ea2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_df5d53147b624d9ca8a65f3c7dfa49f8",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_5fce10c3f9374196969e555c7b13e6b4",
      "value": " 81/81 [01:46&lt;00:00,  1.20it/s]"
     }
    },
    "2c67d6f583a44d0f9e683b4000a20690": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_66df53e3d6594f4f8a1af397c9eba68a",
       "IPY_MODEL_9a3ce94bfaaf4ba8aa90f90fc619fdc1",
       "IPY_MODEL_1cc1b4a0b2114e70b604e0f1d824ea2a"
      ],
      "layout": "IPY_MODEL_d1c66aff2674456b89ee0101135b8d68"
     }
    },
    "5fce10c3f9374196969e555c7b13e6b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "66df53e3d6594f4f8a1af397c9eba68a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bd3319850a8042bba1f7e48cf15509a6",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_0a3bafb7b08d44168524748f38526e70",
      "value": "Processing: 100%"
     }
    },
    "6f9cb4e1456d4ada9e3f98a6ff9f3b74": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a3ce94bfaaf4ba8aa90f90fc619fdc1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6f9cb4e1456d4ada9e3f98a6ff9f3b74",
      "max": 81,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f2e1cd89cb704c5e8c7537b32f1854a2",
      "value": 81
     }
    },
    "bd3319850a8042bba1f7e48cf15509a6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1c66aff2674456b89ee0101135b8d68": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "df5d53147b624d9ca8a65f3c7dfa49f8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f2e1cd89cb704c5e8c7537b32f1854a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
